[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Joshua’s Website",
    "section": "",
    "text": "Welcome to my website! I am an aspiring data scientist actively seeking internships/jobs in the fields of AI, ML, Data Science, and Data Analytics."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Joshua Chen’s Resume",
    "section": "",
    "text": "This is my general resume:\nDownload PDF file.\nThis is my NLP/DL specific resume\nDownload PDF file.\nThis is my Machine Learning specific resume\nDownload PDF file."
  },
  {
    "objectID": "resume.html#resume",
    "href": "resume.html#resume",
    "title": "Joshua Chen’s Resume",
    "section": "Resume",
    "text": "Resume\nfiles/Joshua_Chen_Resume_General.pdf"
  },
  {
    "objectID": "resume.html#this-is-my-current-resume",
    "href": "resume.html#this-is-my-current-resume",
    "title": "Joshua Chen’s Resume",
    "section": "",
    "text": "Resume\nfiles/Joshua_Chen_Resume_General.pdf"
  },
  {
    "objectID": "resume.html#about-this-site",
    "href": "resume.html#about-this-site",
    "title": "Joshua Chen’s Resume",
    "section": "",
    "text": "This is what there is right now."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "index.html#current",
    "href": "index.html#current",
    "title": "Joshua’s Website",
    "section": "Current",
    "text": "Current\n\nTeaching Assistant | UCSD Cognitive Science Department\n\nCogs 108\n\nMachine Learning Capstone Intern | AlphaTrAI"
  },
  {
    "objectID": "index.html#work-history",
    "href": "index.html#work-history",
    "title": "Joshua’s Website",
    "section": "Work History",
    "text": "Work History\n\nAlphaTrAI | 2023 - Present\nTeaching Assistant | 2023 - Present\n\nCogs 108 Data Science in Practice\nCogs 14a Introduction to Research Methods\n\nInstructional Assistant | 2022 - 2023\n\nCogs 18 Introduction to Python\nCogs 1 Introductoi to Cognitive Science"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Joshua’s Website",
    "section": "Education",
    "text": "Education\n\nMS Business Analytics | UC San Diego 2024\nBS Cognitive Science w/ Spec. in Machine Learning | UC San Diego 2023\n\nMagna Cum Laude"
  },
  {
    "objectID": "projects.html#posts",
    "href": "projects.html#posts",
    "title": "My Projects",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "projects.html#summaries",
    "href": "projects.html#summaries",
    "title": "My Projects",
    "section": "Summaries",
    "text": "Summaries\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html#machine-learning",
    "href": "projects.html#machine-learning",
    "title": "My Projects",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "projects.html#marketing-analytics",
    "href": "projects.html#marketing-analytics",
    "title": "My Projects",
    "section": "Marketing Analytics",
    "text": "Marketing Analytics\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nJoshua Chen\n\n\nApr 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nJoshua Chen\n\n\nApr 30, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Sample Project",
    "section": "",
    "text": "import numpy as np\n\n# Use the numpy package\narray = np.array([1, 2, 3, 4, 5])\nprint(array)\n\n[1 2 3 4 5]"
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html",
    "href": "projects/project1/NFL Career Length Predictor.html",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "",
    "text": "This project will analyze data containing NFL player’s draft data and other factors in hopes of creating a machine learning model that will successfully predict a player’s career length. With this data, I also performed a t test to see if 1-2 round draft picks also have a higher career length than 3-5 round picks and 6-7 round picks + undrafted players. These results indicated that 1-2 round draft picks do indeed have a higher career length. However, I was unable to fine tune a model that accurately predicts career length. Future studies should also factor in college data, which this project was unable to do due to the complexities and challenges associated with accessing and integrating college data."
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#note-the-years-of-experience-is-under-the-to-column",
    "href": "projects/project1/NFL Career Length Predictor.html#note-the-years-of-experience-is-under-the-to-column",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "Note: The years of experience is under the ‘To’ Column",
    "text": "Note: The years of experience is under the ‘To’ Column\nFirst we will do a descriptive analysis of the dataset:\n\ndf.describe()\n\nIt appears that the wonderlic score is only available for a select few draftees, upon further research, we realized that wonderlic score is only measured for QBs, therefore, we will be dropping that column from now on.\n\ndf = df.drop(columns = 'Wonderlic')\n\nThen, we take a look at the target variable, years of experience:\n\nplt.hist(df['To'], label = 'Years of Experience')\nplt.title(\"Histogram of Years of Experience\")\nplt.xlabel('Years')\nplt.ylabel('Count')\nplt.show()\n\nFrom this histogram, it appears the target variable is skewed right.\nSince we will be attempting to build a machine learning model, this indicates that we should apply either logarithmic transformation or scaling/normaling to the years of experience in order to imporve the model’s performance.\nNext, we investigate whether or not the years of experience differ for positions.\n\n# Potentially add the count of each position in here\nscores=df[['To','POS']]\nax = scores.boxplot(by='POS', meanline=True, showmeans=True, showcaps=True, \n                showbox=True, showfliers=False, return_type='axes', figsize = (10, 5))\na2 = df[['To','POS']]\na2.boxplot(by='POS', meanline=True, showmeans=True, showcaps=True, \n           showbox=True, showfliers=False, ax=ax)\nplt.ylabel('Years')\nplt.show()\n\nFrom the boxplots, we see that QB and K tend to have the highest career length, while defensive linemen tend to have shorter career length (DL, LB, LS, EDG)\nSurprisingly, one position, OL, does not seem to have a box plot. We are going to investigate for that position.\n\ndf[df['POS'] == 'OL']\n\nIt appears that only one player is listed as an OL, we will be removing this player from the dataset.\n\ndf = df[df['POS'] !='OL']"
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#eda-height",
    "href": "projects/project1/NFL Career Length Predictor.html#eda-height",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "EDA Height",
    "text": "EDA Height\nHere we take a look at the distribution of the heights:\n\nplt.hist(df['Height (in)'], label = 'Height')\nplt.title(\"Histogram of Height\")\nplt.xlabel('Height')\nplt.ylabel('Count')\nplt.show()\n\nWe see the height is normally distributed around 73.5in, without any clear outliers."
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#eda-weight",
    "href": "projects/project1/NFL Career Length Predictor.html#eda-weight",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "EDA Weight",
    "text": "EDA Weight\nHere we take a look at the distribution of the weights:\n\nplt.hist(df['Weight (lbs)'], label = 'Weight')\nplt.title(\"Histogram of Weight\")\nplt.xlabel('Weight')\nplt.ylabel('Count')\nplt.show()\n\nHere we see the weights are somewhat of a bimodal distribution, possibly because linemen positions tend to be heavier than other positions.\n\nscores=df[['Weight (lbs)','POS']]\nax = scores.boxplot(by='POS', meanline=True, showmeans=True, showcaps=True, \n                showbox=True, showfliers=False, return_type='axes', figsize = (10, 5))\na2 = df[['Weight (lbs)','POS']]\na2.boxplot(by='POS', meanline=True, showmeans=True, showcaps=True, \n           showbox=True, showfliers=False, ax=ax)\nplt.ylabel('Weight')\nplt.show()"
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#eda-40-yard",
    "href": "projects/project1/NFL Career Length Predictor.html#eda-40-yard",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "EDA 40 Yard",
    "text": "EDA 40 Yard\nDistribution of 40 yard time:\n\nplt.hist(df['40 Yard'], label = '40 Yard')\nplt.title(\"Histogram of 40 Yard Time\")\nplt.xlabel('Time (s)')\nplt.ylabel('Count')\nplt.show()\n\nSkewed right, possibly becuase linemen tend to have slower times, no clear outliers.\n\nscores=df[['40 Yard','POS']]\nax = scores.boxplot(by='POS', meanline=True, showmeans=True, showcaps=True, \n                showbox=True, showfliers=False, return_type='axes', figsize = (10, 5))\na2 = df[['40 Yard','POS']]\na2.boxplot(by='POS', meanline=True, showmeans=True, showcaps=True, \n           showbox=True, showfliers=False, ax=ax)\nplt.ylabel('40 Yard')\nplt.show()"
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#eda-vertical-leap",
    "href": "projects/project1/NFL Career Length Predictor.html#eda-vertical-leap",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "EDA Vertical Leap",
    "text": "EDA Vertical Leap\n\nplt.hist(df['Vert Leap (in)'], label = 'Vert Leap (in)')\nplt.title(\"Histogram of Vertical Leap\")\nplt.xlabel('inches')\nplt.ylabel('Count')\nplt.show()\n\nThe players’ vertical appears to be a normal distribution."
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#eda-bench-press",
    "href": "projects/project1/NFL Career Length Predictor.html#eda-bench-press",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "EDA Bench Press",
    "text": "EDA Bench Press\n\nplt.hist(df['Bench Press'], label = 'Bench')\nplt.title(\"Histogram of Bench Press\")\nplt.xlabel('Repetitions')\nplt.ylabel('Count')\nplt.show()\n\nThe players’ bench press appears to be a normal distribution."
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#eda-shuttle",
    "href": "projects/project1/NFL Career Length Predictor.html#eda-shuttle",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "EDA Shuttle",
    "text": "EDA Shuttle\n\nplt.hist(df['Shuttle'], label = 'Shuttle')\nplt.title(\"Histogram of Shuttle\")\nplt.xlabel('time (s)')\nplt.ylabel('Count')\nplt.show()\n\nThe players’ shuttle appears to be somewhat of a normal distribution."
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#eda-3cone",
    "href": "projects/project1/NFL Career Length Predictor.html#eda-3cone",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "EDA 3cone",
    "text": "EDA 3cone\n\nplt.hist(df['3Cone'], label = '3Cone')\nplt.title(\"Histogram of 3Cone\")\nplt.xlabel('time (s)')\nplt.ylabel('Count')\nplt.show()\n\nThe players’ 3Cone appears to be somewhat of a normal distribution."
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#eda-age",
    "href": "projects/project1/NFL Career Length Predictor.html#eda-age",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "EDA Age",
    "text": "EDA Age\n\ndf['Age'].value_counts().plot(kind = 'bar')\nplt.title('Barplot of Age')\nplt.xlabel('Years')\nplt.ylabel('Count')\nplt.show()"
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#overall-eda",
    "href": "projects/project1/NFL Career Length Predictor.html#overall-eda",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "Overall EDA",
    "text": "Overall EDA\nWe decided to do a heatmap on all numeric variables and target output:\n\nimport seaborn as sns\nplt.figure(figsize=(12, 12))\nnumeric_cols = ['Height (in)', 'Weight (lbs)', '40 Yard', 'Bench Press', 'Vert Leap (in)', 'Broad Jump (in)', 'Shuttle', '3Cone', 'To', 'Age', 'Pick']\ncorr_numeric = df[numeric_cols].corr()\nsns.heatmap(corr_numeric, cmap='YlGnBu', annot=True, square=True)\n\nIt appears that none of the numeric columns are highly correlated with the target output, years of experience.\n\nfig = pd.plotting.scatter_matrix(df)\nplt.figure(figsize=(16, 16))\nfor ax in fig.ravel():\n    ax.xaxis.label.set_rotation(90)\n    ax.xaxis.label.set_ha('right')\n    ax.xaxis.label.set_va('center')\n\n# Rotate y-axis labels\nfor ax in fig.ravel():\n    ax.yaxis.label.set_rotation(360)\n    ax.yaxis.label.set_ha('right')\n    ax.yaxis.label.set_va('center')\n\nplt.show()\n\nFrom the scatterplots, it appears that while certain variables appear to have somewhat of a correlation with another variables. However, none of them seems to have a clear correlation with years of experience."
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#t-test",
    "href": "projects/project1/NFL Career Length Predictor.html#t-test",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "T test",
    "text": "T test\nWe aim to conduct an inference between the years of experience of 1-2 round draft picks and 3-5 round and 6-7 + undrafted players to determine which round’s player have higher years of experience.\nStudies have shown that players drafted in 1-2 rounds usually play longer than 3-5, which also play longer than 6-7 round picks.\nNote: A lot of teams sign undrafted players to play for a few games, therefore we will not be including the data for undrafted players\nUndrafted players have been assigned a draft pick of 0; from here on, we will assign undrafted players to a pick number of 300. (Each year’s draft all have less than 300 picks).\n\ndef update_pick(x):\n  if int(x) == 0:\n    return 300\n  else:\n    return int(x)\n\n\ndf['Pick'] = df['Pick'].apply(update_pick)\n\nEven though undrafted players are not part of the t-tests, we decided to take a look at the distribution of the years of experience.\n\nund = df[df['Pick'] == 300]\nplt.hist(und['To'], bins = len(und['To'].unique()))\nplt.title('Distribution of undrafted')\n\nEach round have 32 picks. So the top 2 rounds should have 64 picks.\n\ntop2 = df[df['Pick'] &lt;= 64] # dataframe for 1-2 rounders\nmid3 = df[(df['Pick'] &gt; 64) & (df['Pick'] &lt;= 160)] # dataframe for 3-5 rounders\nbot3 = df[(df['Pick'] &gt;160) & (df['Pick'] &lt; 300)] # dataframe for all other\n\n\ntop2.shape\n\n\nmid3.shape\n\n\nbot3.shape\n\nHere we see the distribution of the years of experience for both groups.\n\nplt.hist(top2['To'], bins = len(top2['To'].unique()))\nplt.title('Distribution of top 2 round')\n\n\nplt.hist((mid3['To']), bins = len(mid3['To'].unique()))\nplt.title('Distribution of 3-5 round')\n\n\nplt.hist((bot3['To']), bins = len(bot3['To'].unique()))\nplt.title('Distribution of 6-7 round')\n\nWe see that the distribution of the top 2 rounds is approximately normal, while the distribution of 3-5 round is slightly skewed right, while the distribution of 6-7 round is skewed right.\n\navg_y1 = top2['To'].mean()\navg_y2 = mid3['To'].mean()\navg_y3 = bot3['To'].mean()\n\n\nprint('Average years of experience of 1-2 rounder is ' + str(avg_y1))\nprint('Average years of experience of 3-5 rounder is ' + str(avg_y2))\nprint('Average years of experience of 6-7 rounder is ' + str(avg_y3))\n\n\nfrom scipy.stats import ttest_ind, chisquare, normaltest\n\n\nt-test of 1-2 round and 3-5 round\n\nt_val, p_val = ttest_ind(top2['To'], mid3['To'])\n\n\nif p_val &lt; 0.01:\n    print('There is a significant difference!')\nelse:\n    print('There is NOT a significant difference!')\n\n\n\nt-test of 1-2 round and 6-7 round\n\nt_val, p_val = ttest_ind(top2['To'], bot3['To'])\n\n\nif p_val &lt; 0.01:\n    print('There is a significant difference!')\nelse:\n    print('There is NOT a significant difference!')\n\n\n\nt-test of 3-5 round and 6-7 round\n\nt_val, p_val = ttest_ind(mid3['To'], bot3['To'])\n\n\nif p_val &lt; 0.01:\n    print('There is a significant difference!')\nelse:\n    print('There is NOT a significant difference!')\n\nWe conclude that the study is right: higher drafted players do indeed seem to have longer career lengths."
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#machine-learning-models",
    "href": "projects/project1/NFL Career Length Predictor.html#machine-learning-models",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "Machine Learning Models",
    "text": "Machine Learning Models\n\nPreprocess Data\n\nfrom sklearn.impute import KNNImputer\n\nWe will be using the KNN imputer to impute missing values in the dataset\n\nrandom = df.copy()\n\nWe will be imputing them by positions, to test it out, we will impute the data for only Quarterbacks\n\nrandomQB = random[random['POS'] == 'QB']\nrandomQB.drop(columns = 'Player', inplace = True)\ncollege = randomQB['College_x']\nteam = randomQB['Team']\nrandomQB.drop(columns = ['College_x', 'POS', 'Team'], inplace = True)\nrandomQB.reset_index()\n\n\nrandomQB\n\n\nimputer = KNNImputer(n_neighbors = 5)\nimputer.fit(randomQB)\nrandomQB = pd.DataFrame(imputer.transform(randomQB), columns = randomQB.columns)\nrandomQB['College'] = list(college)\nrandomQB['Team'] = list(team)\nrandomQB\n\n\nrandom['POS'].value_counts()\n\nDL have less than 5 players, for simplicity, we will ignore them.\n\nfilter_list = ['DL']\nrandom = random[~random['POS'].isin(filter_list)]\nrandom\n\nImputer for all positions:\n\nalldf = {}\nallpos = list(random['POS'].unique())\nfor i in allpos:\n  if i !='K' and i !='P':\n    print(i)\n    name = 'random{}'.format(i)\n    subdf = random[random['POS'] ==i]\n    subdf.drop(columns = 'Player', inplace = True)\n    subdf.dropna(subset = 'Pick', inplace = True)\n    college = subdf['College_x']\n    team = subdf['Team']\n    subdf.drop(columns = ['College_x', 'POS', 'Team'], inplace = True)\n    imputer.fit(subdf)\n    subdf = pd.DataFrame(imputer.transform(subdf), columns=subdf.columns)\n    subdf['College'] = list(college)\n    subdf['Team'] = list(team)\n    alldf[name] = subdf\n\nSince Kickers have the shuttle column completely missing, we will have a it separately.\nKickers are most similar to punters, we will be imputing kickers with punters.\n\nrandomKP = random[(random['POS'] == 'K') | (random['POS'] == 'P')]\nrandomKP.drop(columns = 'Player', inplace = True)\ncollege = randomKP['College_x']\nteam = randomKP['Team']\nrandomKP.drop(columns = ['College_x', 'POS', 'Team'], inplace = True)\nrandomKP.reset_index()\nrandomKP\n\n\nimputer = KNNImputer(n_neighbors = 5)\nimputer.fit(randomKP)\nrandomKP = pd.DataFrame(imputer.transform(randomKP), columns = randomKP.columns)\nrandomKP['College'] = list(college)\nrandomKP['Team'] = list(team)\nrandomKP\n\n\nalldf['RandomKP'] = randomKP\n\n\npreprocessed = pd.DataFrame()\nfor df in alldf.values():\n  preprocessed = pd.concat([preprocessed, df])\npreprocessed\n\n\nnan_columns = preprocessed.columns[preprocessed.isna().any()].tolist()\nnan_columns\n\nApparently a few players have np.nan as “College”, we will also drop these rows.\n\npreprocessed = preprocessed.dropna()\npreprocessed\n\n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import recall_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn import svm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, precision_recall_curve, recall_score, precision_score, f1_score,accuracy_score, make_scorer\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import validation_curve\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\nimport warnings\nfrom sklearn.exceptions import FitFailedWarning\nfrom sklearn.exceptions import ConvergenceWarning\n\nOne Hot Encode:\n\npreprocessed = pd.get_dummies(preprocessed)\n\n\nX = preprocessed.drop(columns = ['To']) #DF without years of experience and Total Games Played\ny = preprocessed['To']\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n\nX.head()\n\n\ny.head()"
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#baseline-model---linear-regression",
    "href": "projects/project1/NFL Career Length Predictor.html#baseline-model---linear-regression",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "Baseline Model - Linear Regression",
    "text": "Baseline Model - Linear Regression\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.impute import SimpleImputer\n\n\nfrom sklearn.metrics import accuracy_score, r2_score, mean_squared_error, mean_absolute_error\n\n\nbase = LinearRegression()\n\n\nbase = LinearRegression()\nbase.fit(X_train, y_train)\ny_pred_train = base.predict(X_train)\ny_pred_test = base.predict(X_test)\nprint('Training R2 score:', r2_score(y_train, y_pred_train))\nprint('Testing R2 score:', r2_score(y_test, y_pred_test))\n\n\nplt.scatter(y_pred_train, y_train) #Plot of y_train and y_predicted\nplt.title('prediction on train set')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\n\n\nplt.scatter(y_pred_test, y_test)\nplt.title('prediction on test set')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\n\nIt appears that the problem is too complex for the linear regression to generalize to unseen data."
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#random-forest-regressor",
    "href": "projects/project1/NFL Career Length Predictor.html#random-forest-regressor",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "Random Forest Regressor",
    "text": "Random Forest Regressor\n\nfrom sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor()\nrf.fit(X_train, y_train)\ny_pred_train = rf.predict(X_train)\ny_pred_test = rf.predict(X_test)\nprint('Training R2 score:', r2_score(y_train, y_pred_train))\nprint('Testing R2 score:', r2_score(y_test, y_pred_test))\n\n\nplt.scatter(y_pred_train, y_train) #Plot of y_train and y_predicted\nplt.title('prediction on train set')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\n\n\nplt.scatter(y_pred_test, y_test)\nplt.title('prediction on test set')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\n\nEven though the random forest regressor did pretty well in training, it still does not generalize well to unseen data.\nNow we run a gridsearch to find best combination of hyperparameters that will result in best test score.\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedKFold\n# rf = RandomForestRegressor()\n# param_grid = [{'n_estimators': [100, 200, 300],\n#                'min_samples_split': [2, 5, 10],\n#                'min_samples_leaf': [1, 2, 4],\n#               }]\n# grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='r2', verbose=10)\n# grid_search.fit(X,y)\n\n# print('Best hyperparameters:', grid_search.best_params_)\n# print('Best score:', grid_search.best_score_)\n\n\nBest_hyperparameters= {'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 300}\nBest_score= 0.176639443021116834\n\n\nrf = RandomForestRegressor(min_samples_leaf =4, min_samples_split=2, n_estimators=300, random_state=42)\nrf.fit(X_train, y_train)\ny_pred_train = rf.predict(X_train)\ny_pred_test = rf.predict(X_test)\nprint('Training R2 score:', r2_score(y_train, y_pred_train))\nprint('Testing R2 score:', r2_score(y_test, y_pred_test))\n\n\nplt.scatter(y_pred_train, y_train)\nplt.title('prediction on training set')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\n\n\nplt.scatter(y_pred_test, y_test)\nplt.title('prediction on testing set')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\n\nEven though the new model has a higher test score, when taking a closer look, we see that it’s not able to predict successfully."
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#xgboost-regressor",
    "href": "projects/project1/NFL Career Length Predictor.html#xgboost-regressor",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "XGBoost Regressor",
    "text": "XGBoost Regressor\nXGBoost are ensemble techniques similar to Random Forests, but instead of each model being trained independently, each new model is trained to correct the errors made by the previous models. This model should provide better results than Random Forest.\n\nimport xgboost as xgb\n\n\nxr = xgb.XGBRegressor()\nxr.fit(X_train, y_train)\n\n\ny_pred_train = xr.predict(X_train)\ny_pred_test = xr.predict(X_test)\nprint('Training R2 score:', r2_score(y_train, y_pred_train))\nprint('Testing R2 score:', r2_score(y_test, y_pred_test))\n\n\nplt.scatter(y_pred_train, y_train)\nplt.title('prediction on training set')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\n\n\nplt.scatter(y_pred_test, y_test)\nplt.title('prediction on testing set')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\n\n\nXGBoost does not appear to be a better model than Random Forest Regressors. It appears that the data is simply too complex for the regressors to make predictions.\n\n\nAnother way of evaluating career success is whether or not they play more than 4 years, as 3.3 years is the average length of NFL players.\n\ndef morethan4(x):\n    if int(x) &gt;= 4:\n        return True\n    else:\n        return False\n\n\npreprocessed['To'] = preprocessed['To'].apply(morethan4)\n\n\npreprocessed.head()\n\n\npreprocessed['To'].value_counts(True)\n\n\nX = preprocessed.drop(columns = 'To') #DF without years of experience\ny = preprocessed['To']\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#knn-classifier",
    "href": "projects/project1/NFL Career Length Predictor.html#knn-classifier",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "KNN Classifier",
    "text": "KNN Classifier\n\n#imports for knn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\nValidation curve for how many neighbors:\n\nk_range = [10,50,60,70,100,150]\ntrain_scores, val_scores = validation_curve(KNeighborsClassifier(), X_train, y_train, \n                                             param_name='n_neighbors', \n                                             param_range=k_range)\n\n# Plot validation curve\nplt.figure(figsize=(10, 6))\nplt.title(\"KNN Validation Curve\")\nplt.xlabel(\"K\")\nplt.ylabel(\"Accuracy\")\nplt.xticks(k_range)\nplt.plot(k_range, np.median(train_scores, 1), color='blue', label='training score')\nplt.plot(k_range, np.median(val_scores, 1), color='red', label='validation score')\nplt.legend(loc=\"best\")\nplt.show()\n\nIt appears k neighbors of about 50-70 is the sweet spot; we will use neighbors of 50.\n\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score, roc_curve\n# train the KNN classifier\nknn = KNeighborsClassifier(n_neighbors=50, metric='euclidean')\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nprint(\"The accuracy score for this model is:\", metrics.accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\ncm2 = metrics.confusion_matrix(y_test, y_pred)\n\nfig, ax = plt.subplots(figsize=(7.5, 7.5))\nax.matshow(cm2, cmap=plt.cm.Blues, alpha=0.3)\nfor i in range(cm2.shape[0]):\n    for j in range(cm2.shape[1]):\n        ax.text(x=j, y=i,s=cm2[i, j], va='center', ha='center', size='xx-large')\n\nplt.xlabel('Predictions', fontsize=18)\nplt.ylabel('Actuals', fontsize=18)\nplt.title('Confusion Matrix', fontsize=18)\nplt.show()\nrecall = recall_score(y_test, y_pred, pos_label=True)\nprecision = precision_score(y_test, y_pred, pos_label=True)\nf1 = f1_score(y_test, y_pred, pos_label=True)\nprint(\"Recall:\", recall)\nprint(\"Precision:\", precision)\nprint(\"F1 score:\", f1)\n\n\nfrom sklearn.feature_selection import SelectKBest, f_classif\nselector = SelectKBest(f_classif, k=5) # k specifies the number of top features to select\nselector.fit(X_test, y_test)\nX_selected = selector.transform(X_test)\n\nknn.fit(X_selected, y_test)\n\n# Print the importance of each feature\nfeature_importance = selector.scores_\ntop_feature_indices = selector.get_support(indices=True)\n\n# Get the names of the top features\ntop_feature_names = [X.columns[i] for i in top_feature_indices]\n\n\n# Print the name of the most important feature\ntop_feature_names\n\nFrom the application of SelectKBest to KNN model, age of draft, pick number, and whether or not a person is undrafted seem to be the main feature of importance. This indicates that the higher the pick number, the higher the chances of the player playing over 4 years, which is what we would expect. Surprisingly, bench press seeemed to matter too.\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import VarianceThreshold\npipe = Pipeline([\n('scaler', StandardScaler()),\n('selector', VarianceThreshold()),\n('classifier', KNeighborsClassifier())\n])\n\npipe.fit(X_train, y_train)\nprint('Training set score: ' + str(pipe.score(X_train,y_train)))\nprint('Test set score: ' + str(pipe.score(X_test,y_test)))\n\nGridsearching best n neighbors; from the validation curve, its between 50-70.\n\nfrom sklearn.model_selection import GridSearchCV\n\nparameters = {\n 'classifier__n_neighbors': [50, 55, 60, 65, 70]\n}\n# create grid search\ngrid = GridSearchCV(pipe, parameters,scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'],\n                    cv=5, n_jobs = -1, refit=False,verbose=0).fit(X_train, y_train)\n\n\nbest_model = grid.fit(X_train, y_train)\n# get the model with highest accuracy from grid search\np_accu = best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ]\np_accu\n\n\npipe.set_params(**p_accu)\n\n\n# train on the entire training set with the model with highest accuracy from grid search\nclf = pipe.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nscore2 = clf.score(X_test, y_test)\nprint(\"The accuracy score for the optimized model is\", score2)\ncm5 = metrics.confusion_matrix(y_test, y_pred)\n\nfig, ax = plt.subplots(figsize=(7.5, 7.5))\nax.matshow(cm5, cmap=plt.cm.Blues, alpha=0.3)\nfor i in range(cm5.shape[0]):\n    for j in range(cm5.shape[1]):\n        ax.text(x=j, y=i,s=cm5[i, j], va='center', ha='center', size='xx-large')\n\nplt.xlabel('Predictions', fontsize=18)\nplt.ylabel('Actuals', fontsize=18)\nplt.title('Confusion Matrix', fontsize=18)\nplt.show()\nfpr = roc_curve(y_test, clf.predict_proba(X_test)[:,1], pos_label=True)[0] # false positiv \ntpr = roc_curve(y_test, clf.predict_proba(X_test)[:,1], pos_label=True)[1] # true positive \nroc_auc2 = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n\nKNN seems to be somewhat good at classifying; however, we see that the model is making quite a lot of false positive predicitons.\nNow we use a random forest classifier to see if can be more accurate than the KNN and make less false positives.\n\nRandom Forest Classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nclf = rf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nscore2 = clf.score(X_test, y_test)\nprint(\"The accuracy score for the optimized model is\", score2)\ncm5 = metrics.confusion_matrix(y_test, y_pred)\n\nfig, ax = plt.subplots(figsize=(7.5, 7.5))\nax.matshow(cm5, cmap=plt.cm.Blues, alpha=0.3)\nfor i in range(cm5.shape[0]):\n    for j in range(cm5.shape[1]):\n        ax.text(x=j, y=i,s=cm5[i, j], va='center', ha='center', size='xx-large')\n\nplt.xlabel('Predictions', fontsize=18)\nplt.ylabel('Actuals', fontsize=18)\nplt.title('Confusion Matrix', fontsize=18)\nplt.show()\nfpr = roc_curve(y_test, clf.predict_proba(X_test)[:,1], pos_label=True)[0] # false positiv \ntpr = roc_curve(y_test, clf.predict_proba(X_test)[:,1], pos_label=True)[1] # true positive \nroc_auc2 = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n\nIt appears that the random forest has increased accuracy and decreased the false positive rate, but also increased false negatives.\n\n\nGridsearch for Random Forest Classifier\n\n# param_grid = {\n#     'n_estimators': [100, 200, 300],\n#     'max_depth': [None, 5, 10],\n#     'min_samples_split': [2, 4, 6],\n#     'min_samples_leaf': [1, 2, 3]\n# }\n\n# # Create a random forest classifier\n# rf = RandomForestClassifier(random_state=42)\n\n# # Perform grid search\n# grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', verbose=10)\n# grid_search.fit(X_train, y_train)\n\n\n# Get the best parameters and best score\n# best_params = grid_search.best_params_\n# best_score = grid_search.best_score_\n\n# print(\"Best Parameters:\", best_params)\n# print(\"Best Score:\", best_score)\n\nBest Parameters: {‘max_depth’: None, ‘min_samples_leaf’: 2, ‘min_samples_split’: 6, ‘n_estimators’: 200}\nBest Score: 0.6890196078431373\n\nrf = RandomForestClassifier(max_depth = None, min_samples_leaf = 2, min_samples_split = 6, n_estimators = 200, random_state=42)\nclf = rf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nscore2 = clf.score(X_test, y_test)\nprint(\"The accuracy score for the optimized model is\", score2)\ncm5 = metrics.confusion_matrix(y_test, y_pred)\n\nfig, ax = plt.subplots(figsize=(7.5, 7.5))\nax.matshow(cm5, cmap=plt.cm.Blues, alpha=0.3)\nfor i in range(cm5.shape[0]):\n    for j in range(cm5.shape[1]):\n        ax.text(x=j, y=i,s=cm5[i, j], va='center', ha='center', size='xx-large')\n\nplt.xlabel('Predictions', fontsize=18)\nplt.ylabel('Actuals', fontsize=18)\nplt.title('Confusion Matrix', fontsize=18)\nplt.show()"
  },
  {
    "objectID": "projects/project1/NFL Career Length Predictor.html#random-forest-top-100-feature-selection-for-adaboost-classifier",
    "href": "projects/project1/NFL Career Length Predictor.html#random-forest-top-100-feature-selection-for-adaboost-classifier",
    "title": "Predicting NFL PLayers’ Career Length",
    "section": "Random Forest Top 100 Feature Selection for Adaboost Classifier",
    "text": "Random Forest Top 100 Feature Selection for Adaboost Classifier\n\nfrom sklearn.feature_selection import RFE\n\nestimator = RandomForestClassifier(n_estimators=100)\nselector = RFE(estimator, n_features_to_select=100)\nX_new = selector.fit_transform(X, y)\n\n\nX_new\n\n\nselected_feature_indices = selector.support_\n\n# Get the names or column indices of the selected features\nselected_feature_names = [name for name, selected in zip(X.columns, selected_feature_indices) if selected]\nselected_feature_indices = [idx for idx, selected in enumerate(selected_feature_indices) if selected]\n\nprint(\"Selected Feature Names:\", selected_feature_names)\nprint(\"Selected Feature Indices:\", selected_feature_indices)\n\n\nX_new = pd.DataFrame(X_new, columns = selected_feature_names)\n\n\n#Resplitting the data\nX_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)\n\n\nfrom sklearn.ensemble import AdaBoostClassifier\n\n\nensemble = AdaBoostClassifier(base_estimator = rf)\nclf = ensemble.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nscore2 = clf.score(X_test, y_test)\nprint(\"The accuracy score for the optimized model is\", score2)\ncm5 = metrics.confusion_matrix(y_test, y_pred)\n\nfig, ax = plt.subplots(figsize=(7.5, 7.5))\nax.matshow(cm5, cmap=plt.cm.Blues, alpha=0.3)\nfor i in range(cm5.shape[0]):\n    for j in range(cm5.shape[1]):\n        ax.text(x=j, y=i,s=cm5[i, j], va='center', ha='center', size='xx-large')\n\nplt.xlabel('Predictions', fontsize=18)\nplt.ylabel('Actuals', fontsize=18)\nplt.title('Confusion Matrix', fontsize=18)\nplt.show()\n\n\nGridsearch\n\n# param_grid = {\n#     'n_estimators': [50, 100, 150],\n#     'learning_rate': [0.1, 0.5, 1.0]\n# }\n\n# # Perform grid search using cross-validation\n# grid_search = GridSearchCV(ensemble, param_grid, cv=5, verbose = 10)\n# grid_search.fit(X_train, y_train)\n\n# # Get the best parameters and best score from grid search\n# best_params = grid_search.best_params_\n# best_score = grid_search.best_score_\n# print(\"Best Parameters:\", best_params)\n# print(\"Best Score:\", best_score)\n\n\nensemble = AdaBoostClassifier(base_estimator = rf, learning_rate = 0.5, n_estimators = 100)\nclf = ensemble.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nscore2 = clf.score(X_test, y_test)\nprint(\"The accuracy score for the optimized model is\", score2)\ncm5 = metrics.confusion_matrix(y_test, y_pred)\n\nfig, ax = plt.subplots(figsize=(7.5, 7.5))\nax.matshow(cm5, cmap=plt.cm.Blues, alpha=0.3)\nfor i in range(cm5.shape[0]):\n    for j in range(cm5.shape[1]):\n        ax.text(x=j, y=i,s=cm5[i, j], va='center', ha='center', size='xx-large')\n\nplt.xlabel('Predictions', fontsize=18)\nplt.ylabel('Actuals', fontsize=18)\nplt.title('Confusion Matrix', fontsize=18)\nplt.show()\n\n\n\nFeature Importance\n\nimportances = ensemble.feature_importances_\nindices = np.argsort(importances)[::-1]\nfeature_names = X_new.columns\n\n\nfor idx in indices[0:10]:\n    print(f\"Feature: {feature_names[idx]}, Importance: {importances[idx]}\")"
  },
  {
    "objectID": "projects/project1/coord.html",
    "href": "projects/project1/coord.html",
    "title": "Coordinate Descent",
    "section": "",
    "text": "The goal of this project is to come up with a new coordinate descent method. Coordinate descent simplifies optimization problems by iteratively focusing on one coordinate at a time, making it efficient for large-scale and high-dimensional datasets. Its simplicity and adaptability to different problem structures lead to faster convergence and reduced computational costs.\nTo test the efficiency of my coordinate descent method, I used the wine dataset on UCI repo and only focused on the first and second class, making it a binary classification probllem."
  },
  {
    "objectID": "projects/project1/coord.html#model-1",
    "href": "projects/project1/coord.html#model-1",
    "title": "Coordinate Descent",
    "section": "Model 1",
    "text": "Model 1\nOnly the coordinate with the largest gradient (i.e., the steepest slope) is selected for optimization in each iteration.\n\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\n\ndef coordinate_descent_lr(X, y, method='largest_gradient', num_iterations=100, learning_rate=0.01):\n    n_samples, n_features = X.shape\n    w = np.zeros(n_features)\n    b = 0\n    losses = []\n\n    for _ in range(num_iterations):\n        for i in range(n_features):\n            if method == 'random':\n                i = np.random.randint(n_features)  # Random feature for random-feature coordinate descent\n            else:\n                y_pred = sigmoid(np.dot(X, w) + b)\n                gradients = -np.dot(X.T, (y-y_pred)) / n_samples\n                i = np.argmax(np.abs(gradients))\n                \n            feature = X[:, i]\n            y_pred = sigmoid(np.dot(X, w) + b)\n\n            # Gradient calculation\n            grad_wi = -np.dot(feature, (y - y_pred)) / n_samples\n            grad_b = -np.mean(y - y_pred)\n\n            # Update weights\n            w[i] -= learning_rate * grad_wi\n            b -= learning_rate * grad_b\n\n        # Record the loss after each full iteration over features\n        losses.append(log_loss(y, sigmoid(np.dot(X, w) + b)))\n\n    return w, b, losses"
  },
  {
    "objectID": "projects/project1/coord.html#model-2",
    "href": "projects/project1/coord.html#model-2",
    "title": "Coordinate Descent",
    "section": "Model 2",
    "text": "Model 2\nRandomly choose a single coordinate to optimize in each iteration Note: Code is the same as above, change method to random instead."
  },
  {
    "objectID": "projects/project1/coord.html#algorithm-1",
    "href": "projects/project1/coord.html#algorithm-1",
    "title": "Coordinate Descent",
    "section": "Algorithm 1",
    "text": "Algorithm 1\nOnly the coordinate with the largest gradient (i.e., the steepest slope) is selected for optimization in each iteration.\n\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\n\ndef coordinate_descent_lr(X, y, method='largest_gradient', num_iterations=100, learning_rate=0.01):\n    n_samples, n_features = X.shape\n    w = np.zeros(n_features)\n    b = 0\n    losses = []\n\n    for _ in range(num_iterations):\n        for i in range(n_features):\n            if method == 'random':\n                i = np.random.randint(n_features)  # Random feature for random-feature coordinate descent\n            else:\n                y_pred = sigmoid(np.dot(X, w) + b)\n                gradients = -np.dot(X.T, (y-y_pred)) / n_samples\n                i = np.argmax(np.abs(gradients))\n                \n            feature = X[:, i]\n            y_pred = sigmoid(np.dot(X, w) + b)\n\n            # Gradient calculation\n            grad_wi = -np.dot(feature, (y - y_pred)) / n_samples\n            grad_b = -np.mean(y - y_pred)\n\n            # Update weights\n            w[i] -= learning_rate * grad_wi\n            b -= learning_rate * grad_b\n\n        # Record the loss after each full iteration over features\n        losses.append(log_loss(y, sigmoid(np.dot(X, w) + b)))\n\n    return w, b, losses"
  },
  {
    "objectID": "projects/project1/coord.html#algorithm-2",
    "href": "projects/project1/coord.html#algorithm-2",
    "title": "Coordinate Descent",
    "section": "Algorithm 2",
    "text": "Algorithm 2\nRandomly choose a single coordinate to optimize in each iteration Note: Code is the same as above, change method to random instead."
  },
  {
    "objectID": "projects/project1/coord.html#simple-update",
    "href": "projects/project1/coord.html#simple-update",
    "title": "Coordinate Descent",
    "section": "Simple Update",
    "text": "Simple Update\nAt each step, weights is updated with the formula \\(w_i \\leftarrow w_i - \\alpha \\frac{\\partial L}{\\partial w_i}\\), where \\(\\frac{\\partial L}{\\partial w_i}\\) is the partial derivative of loss function L with respect to \\(w_i\\) ## Backtracking Line Search Back tracking line search adatively adjusts the learning rate, ensuring each step in the optimization process is sufficiently large to make progress yet small enough to avoid overshooting minimum.\n\ndef backtracking_line_search(X, y, w, b, grad_wi, i, initial_lr=1, beta=0.8, c=1e-4):\n    lr = initial_lr\n    current_loss = log_loss(y, sigmoid(np.dot(X, w) + b))\n    updated_w = w.copy()\n    \n    while True:\n        updated_w[i] = w[i] - lr * grad_wi\n        new_loss = log_loss(y, sigmoid(np.dot(X, updated_w) + b))\n        if new_loss &lt;= current_loss - c * lr * grad_wi**2:\n            break\n        lr *= beta\n    \n    return lr\n\nImplementing it into Coordinate Descent algorithm above gives:\n\ndef coordinate_descent_lr2(X, y, method='largest_gradient', num_iterations=100):\n    n_samples, n_features = X.shape\n    w = np.zeros(n_features)\n    b = 0\n    losses = []\n\n    for _ in range(num_iterations):\n        for i in range(n_features):\n            if method == 'largest_gradient':\n                y_pred = sigmoid(np.dot(X, w) + b)\n                gradients = -np.dot(X.T, (y - y_pred)) / n_samples\n                i = np.argmax(np.abs(gradients))\n            else:\n                i = np.random.randint(n_features)\n\n            feature = X[:, i]\n            y_pred = sigmoid(np.dot(X, w) + b)\n            grad_wi = -np.dot(feature, (y - y_pred)) / n_samples\n            grad_b = -np.mean(y - y_pred)\n\n            # Backtracking line search to find learning rate\n            learning_rate_wi = backtracking_line_search(X, y, w, b, grad_wi, i)\n\n            # Update weights\n            w[i] -= learning_rate_wi * grad_wi\n            b -= learning_rate_wi * grad_b\n\n        losses.append(log_loss(y, sigmoid(np.dot(X, w) + b)))\n\n    return w, b, losses"
  },
  {
    "objectID": "projects/project1/proto.html",
    "href": "projects/project1/proto.html",
    "title": "Prototype Selection",
    "section": "",
    "text": "The goal of this project is to find a way to down sample to size n from an entire training set so that the training time for the nearest neighbor could be reduced while remaining the accuracy of the original training set.\nThe algorithms are tested on the MNIST dataset."
  },
  {
    "objectID": "projects/project1/proto.html#algorithm-1",
    "href": "projects/project1/proto.html#algorithm-1",
    "title": "Prototype Selection",
    "section": "Algorithm 1",
    "text": "Algorithm 1\nK-Means Clustering 1: Split the dataset into 10 clusters (as there are 10 digits) and take an equal amount of datapoints from each cluster as the subsample"
  },
  {
    "objectID": "projects/project1/proto.html#algorithm-2",
    "href": "projects/project1/proto.html#algorithm-2",
    "title": "Prototype Selection",
    "section": "Algorithm 2",
    "text": "Algorithm 2\nK-Means Clustering 2: Split the dataset into n clusters and take one datapoint from each cluster as the subsample"
  },
  {
    "objectID": "projects/project1/proto.html#algorithm-3",
    "href": "projects/project1/proto.html#algorithm-3",
    "title": "Prototype Selection",
    "section": "Algorithm 3",
    "text": "Algorithm 3\nModified Active Learning: Randomly select datapoints and run a classification model and select the most uncertain datapoints."
  },
  {
    "objectID": "projects/project1/proto.html#algorithm-4",
    "href": "projects/project1/proto.html#algorithm-4",
    "title": "Prototype Selection",
    "section": "Algorithm 4",
    "text": "Algorithm 4\nModified K-Means: Subsample proportionately to training, identify digits that are likely to be misclassified and apply K-means to clustered digits"
  },
  {
    "objectID": "projects.html#natural-language-processing",
    "href": "projects.html#natural-language-processing",
    "title": "My Projects",
    "section": "Natural Language Processing",
    "text": "Natural Language Processing\n\n\n\n\n\n\n\n\n\n\nRestaurant Category Prediction\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/nlp/restaurant.html",
    "href": "projects/nlp/restaurant.html",
    "title": "Restaurant Category Prediction",
    "section": "",
    "text": "The goal of this project is to predict the restaurant type using details about the restaurant and their reviews. There is also a Kaggle Competition Page associated with this project.\n\n\nThis is my position on the Kaggle Leader Board:"
  },
  {
    "objectID": "projects/nlp/restaurant.html#leaderboard",
    "href": "projects/nlp/restaurant.html#leaderboard",
    "title": "Restaurant Category Prediction",
    "section": "",
    "text": "This is my position on the Kaggle Leader Board:"
  },
  {
    "objectID": "projects/MA/hw1_questions.html",
    "href": "projects/MA/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn their experiment, Dean Karlan and John A. List conducted a large-scale natural field experiment to explore the impact of price on charitable giving. They used direct mail solicitations sent to over 50,000 previous donors of a nonprofit organization to test the effectiveness of matching grants on charitable donations. The experiment randomly assigned individuals to either a control group or a matching grant treatment group. Within the matching grant treatment group, individuals were further randomly assigned to different matching grant rates, matching grant maximum amounts, and suggested donation amounts.\nThe study found that announcing the availability of match money significantly increased both the revenue per solicitation (by 19%) and the probability of making a donation (by 22%). However, larger matching ratios ($3:$1 and $2:$1) did not have an additional impact compared to a smaller matching ratio ($1:$1). The elasticity estimate of the price change from the baseline to the treatment groups was -0.30, which is near the lower range of the elasticity of giving with respect to transitory price changes reported in previous studies.\nInterestingly, the effectiveness of the matching gift varied by the political environment of the donors. In states that voted for George W. Bush in the 2004 presidential election (“red” states), the match increased the revenue per solicitation by 55%, while in “blue” states, there was little effect observed.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/MA/hw1_questions.html#introduction",
    "href": "projects/MA/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn their experiment, Dean Karlan and John A. List conducted a large-scale natural field experiment to explore the impact of price on charitable giving. They used direct mail solicitations sent to over 50,000 previous donors of a nonprofit organization to test the effectiveness of matching grants on charitable donations. The experiment randomly assigned individuals to either a control group or a matching grant treatment group. Within the matching grant treatment group, individuals were further randomly assigned to different matching grant rates, matching grant maximum amounts, and suggested donation amounts.\nThe study found that announcing the availability of match money significantly increased both the revenue per solicitation (by 19%) and the probability of making a donation (by 22%). However, larger matching ratios ($3:$1 and $2:$1) did not have an additional impact compared to a smaller matching ratio ($1:$1). The elasticity estimate of the price change from the baseline to the treatment groups was -0.30, which is near the lower range of the elasticity of giving with respect to transitory price changes reported in previous studies.\nInterestingly, the effectiveness of the matching gift varied by the political environment of the donors. In states that voted for George W. Bush in the 2004 presidential election (“red” states), the match increased the revenue per solicitation by 55%, while in “blue” states, there was little effect observed.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/MA/hw1_questions.html#data",
    "href": "projects/MA/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\n(50083, 51)\n\n\nThere are 50083 rows and 51 columns in this dataset.\n\n\n           treatment       control    ratio        ratio2        ratio3  \\\ncount   50083.000000  50083.000000    50083  50083.000000  50083.000000   \nunique           NaN           NaN        4           NaN           NaN   \ntop              NaN           NaN  Control           NaN           NaN   \nfreq             NaN           NaN    16687           NaN           NaN   \nmean        0.666813      0.333187      NaN      0.222311      0.222211   \nstd         0.471357      0.471357      NaN      0.415803      0.415736   \nmin         0.000000      0.000000      NaN      0.000000      0.000000   \n25%         0.000000      0.000000      NaN      0.000000      0.000000   \n50%         1.000000      0.000000      NaN      0.000000      0.000000   \n75%         1.000000      1.000000      NaN      0.000000      0.000000   \nmax         1.000000      1.000000      NaN      1.000000      1.000000   \n\n           size        size25        size50       size100        sizeno  ...  \\\ncount     50083  50083.000000  50083.000000  50083.000000  50083.000000  ...   \nunique        5           NaN           NaN           NaN           NaN  ...   \ntop     Control           NaN           NaN           NaN           NaN  ...   \nfreq      16687           NaN           NaN           NaN           NaN  ...   \nmean        NaN      0.166723      0.166623      0.166723      0.166743  ...   \nstd         NaN      0.372732      0.372643      0.372732      0.372750  ...   \nmin         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n25%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n50%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n75%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \nmax         NaN      1.000000      1.000000      1.000000      1.000000  ...   \n\n              redcty       bluecty        pwhite        pblack     page18_39  \\\ncount   49978.000000  49978.000000  48217.000000  48047.000000  48217.000000   \nunique           NaN           NaN           NaN           NaN           NaN   \ntop              NaN           NaN           NaN           NaN           NaN   \nfreq             NaN           NaN           NaN           NaN           NaN   \nmean        0.510245      0.488715      0.819599      0.086710      0.321694   \nstd         0.499900      0.499878      0.168561      0.135868      0.103039   \nmin         0.000000      0.000000      0.009418      0.000000      0.000000   \n25%         0.000000      0.000000      0.755845      0.014729      0.258311   \n50%         1.000000      0.000000      0.872797      0.036554      0.305534   \n75%         1.000000      1.000000      0.938827      0.090882      0.369132   \nmax         1.000000      1.000000      1.000000      0.989622      0.997544   \n\n           ave_hh_sz  median_hhincome        powner  psch_atlstba  \\\ncount   48221.000000     48209.000000  48214.000000  48215.000000   \nunique           NaN              NaN           NaN           NaN   \ntop              NaN              NaN           NaN           NaN   \nfreq             NaN              NaN           NaN           NaN   \nmean        2.429012     54815.700533      0.669418      0.391661   \nstd         0.378115     22027.316665      0.193405      0.186599   \nmin         0.000000      5000.000000      0.000000      0.000000   \n25%         2.210000     39181.000000      0.560222      0.235647   \n50%         2.440000     50673.000000      0.712296      0.373744   \n75%         2.660000     66005.000000      0.816798      0.530036   \nmax         5.270000    200001.000000      1.000000      1.000000   \n\n        pop_propurban  \ncount    48217.000000  \nunique            NaN  \ntop               NaN  \nfreq              NaN  \nmean         0.871968  \nstd          0.258654  \nmin          0.000000  \n25%          0.884929  \n50%          1.000000  \n75%          1.000000  \nmax          1.000000  \n\n[11 rows x 51 columns]\n\n\nThe above shows a general distribution for each variable.\n\n\ntreatment                0\ncontrol                  0\nratio                    0\nratio2                   0\nratio3                   0\nsize                     0\nsize25                   0\nsize50                   0\nsize100                  0\nsizeno                   0\nask                      0\naskd1                    0\naskd2                    0\naskd3                    0\nask1                     0\nask2                     0\nask3                     0\namount                   0\ngave                     0\namountchange             0\nhpa                      0\nltmedmra                 0\nfreq                     0\nyears                    1\nyear5                    0\nmrm2                     1\ndormant                  0\nfemale                1111\ncouple                1148\nstate50one               0\nnonlit                 452\ncases                  452\nstatecnt                 0\nstateresponse            0\nstateresponset           0\nstateresponsec           3\nstateresponsetminc       3\nperbush                 35\nclose25                 35\nred0                    35\nblue0                   35\nredcty                 105\nbluecty                105\npwhite                1866\npblack                2036\npage18_39             1866\nave_hh_sz             1862\nmedian_hhincome       1874\npowner                1869\npsch_atlstba          1868\npop_propurban         1866\ndtype: int64\n\n\nThis shows the number of missing values in each column.\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nTesting mrm2 - Months since last donation.\n\n\nT-test results: t-statistic = 0.11953155228177251, p-value = 0.9048549631450832\n\n\n\n\nLinear regression results:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Tue, 16 Apr 2024   Prob (F-statistic):              0.905\nTime:                        13:04:47   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n13.011828117981734\n12.99814226643495\n\n\nUsing both the t-test and linear regerssion, the p-value for the difference in mens between treatment and control groups for mrm2 is 0.905. This means that we fail to reject the null hypothesis that the treatment and control groups are statistically significantly different at the 95% confidence level, further suggesting that the randomization was successful.\n\n\nmean for mrm2 control: 12.99814226643495\nmean for mrm2 control: 13.011828117981734\n\n\nThe above values matches the ones shown in Table 1.\n\n\nTesting hpa - highest previous contribution\n\n\nT-test results: t-statistic = 0.9704273843087994, p-value = 0.3318400397145116\n\n\n\n\nLinear regression results:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                    hpa   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.8924\nDate:                Tue, 16 Apr 2024   Prob (F-statistic):              0.345\nTime:                        13:04:47   Log-Likelihood:            -2.8468e+05\nNo. Observations:               50083   AIC:                         5.694e+05\nDf Residuals:                   50081   BIC:                         5.694e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     58.9602      0.551    107.005      0.000      57.880      60.040\ntreatment      0.6371      0.675      0.944      0.345      -0.685       1.960\n==============================================================================\nOmnibus:                    66199.149   Durbin-Watson:                   2.003\nProb(Omnibus):                  0.000   Jarque-Bera (JB):         14448195.271\nSkew:                           7.552   Prob(JB):                         0.00\nKurtosis:                      84.826   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n59.59724\n58.960167\n\n\nUsing both the t-test and linear regerssion, the p-value for the difference in mens between treatment and control groups for hpa are both above 0.94. This means that we fail to reject the null hypothesis that the treatment and control groups are statistically significantly different at the 95% confidence level, further suggesting that the randomization was successful.\n\n\nmean for mrm2 control: 58.960167\nmean for mrm2 control: 59.59724\n\n\nThe above values matches the ones shown in Table 1.  Note: hpa is highest previous contribution and mrm2 is number of months since last donation."
  },
  {
    "objectID": "projects/MA/hw1_questions.html#experimental-results",
    "href": "projects/MA/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\n\n\n\n\n\n\n\nAs seen in the plot above, the control group appears to have a lower proportion compared to the treatment group.\n\n\nT-test results: t-statistic = 3.101361000543946, p-value = 0.0019274025949016982\nLinear regression results:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Tue, 16 Apr 2024   Prob (F-statistic):            0.00193\nTime:                        13:04:47   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThe t-test and linear regression both show a p value of 0.002. This suggest that the difference in response rates between the treatment and control groups is statistically significant, meaning that the treatment group does indeed increase the likelihood of making a charitable donation compared to the control group. This finding is also consistent with the results reported in Table 2a.\n\n\ncoefficient 0.004180354512949377\nz-statistic:  3.101361000543931\np-value:  0.001927402594901797\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Tue, 16 Apr 2024   Prob (F-statistic):            0.00193\nTime:                        13:04:47   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThe probit regression also confirms that the coefficient on the treatment varialbe is statistically significant (coefficient of 0.004 and p-value of 0.002). This is consistent with the findings on Table 3 column 1, suggesting that people in the treatemnt group does have increased likelihood of making a charitable donation. However, it is do be noted that while Table 3 indicates the use of Probit regression, the above was replicated with a linear regression.\nThe results of a probit regression is shown below:\n\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\ncoefficient 0.08678462244745795\nz-statistic:  3.112930073794974\np-value:  0.0018523990147786566\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Tue, 16 Apr 2024   Pseudo R-squ.:               0.0009783\nTime:                        13:04:48   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\nWhile the coefficient is not the same as that on Table 3 column 1, the p-value is still 0.002, indicating that people in the treatment group does have increased likelihood of making a charitable donation.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n\n1:1 and 2:1 match ratiosT-test results: t-statistic = 0.05011583793874515, p-value = 0.9600305283739325\n1:1 and 3:1 match ratiosT-test results: t-statistic = -1.0150255853798622, p-value = 0.3101046637086672\n1:1 and 2:1 match ratiosT-test results: t-statistic = -0.96504713432247, p-value = 0.33453168549723933\n\n\nThe t-tests and the p-values show that the difference in response rate betwen 1:1 and 2:1, 2:1 and 3:1, 1:1 and 3:1 are all not statistically significant at the 95% confidence level. This means that the match ratios does not increase the likelihood of someone making a charitable donation. This is consistent with the authors comments on page 8, which suggested that the figures do not show a clear pattern of increasing repsonse rates as match ratios increase.\n\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.665\nDate:                Tue, 16 Apr 2024   Prob (F-statistic):             0.0118\nTime:                        13:04:48   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.322e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.0179      0.001     16.225      0.000       0.016       0.020\nratio1         0.0029      0.002      1.661      0.097      -0.001       0.006\nratio2         0.0048      0.002      2.744      0.006       0.001       0.008\nratio3         0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\nOmnibus:                    59812.754   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4316693.217\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.438   Cond. No.                         4.26\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThe regression results indicate that the coefficients for the 2:1 and 3:1 match ratios are statistically significant at the 95% confidence interval, suggesting that these match sizes significantly increase the likelihood of donating compared to the baseline category, which is the control group. However, the coefficient for the 1:1 match ratio is not statistically significant, indicating that a 1:1 match does not significantly enhance the likelihood of donating when compared to no matching. Therefore, while the 2:1 and 3:1 matches are effective in increasing donation rates, the 1:1 match does not show a significant effect relative to having no match at all.\n\n\ndifference between 3:1 and 2:1 : 0.00010002398025293902\ndifference between 1:1 and 2:1 : -0.0018842510217149944\ndifference between 3:1 and 1:1 : 0.0019842750019679334\n\n\nThe above is calcualted directly from data\n\n\ndifference between 3:1 and 2:1 : 0.00010002398025313504\ndifference between 1:1 and 2:1 : -0.0018842510217151158\ndifference between 3:1 and 1:1 : 0.001984275001968251\n\n\nThe above is calculated using the coefficients generated from the regression above.\nBoth resulted in the same set of numbers.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n\ndifference in donation amounts between control and treatment:  0.1536054\nt-statistic:  1.8605020225753781\np-value:  0.06282038947470686\n\n\nThe p-value suggest that the difference in donation amount between the treatment and control group is not statistically significant at the 95% confidence level. This suggests that the treatment group does not appear to have a higher donation amount.\n\n\ndifference in donation amounts between control and treatment:  -1.6683922\nt-statistic:  -0.5808388615237938\np-value:  0.5614758782284279\n\n\nNow limiting to only the people that donated, it appears that the treatment group donates about 1.66 units less than the control group. This different is not statistically significant though, as the p-value is 0.5615, well above the 0.05 threshold. Therefore, we cannot confidently assert the causal interpretation that people receiving treatment will result in reduced donation amounts."
  },
  {
    "objectID": "projects/MA/hw1_questions.html#simulation-experiment",
    "href": "projects/MA/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\n\n\n\n\n\n\n\n\nIn this plot, the x-axis represents the number of draws, and the y-axis represents the cumulative average of the differences between the treatment and control draws. The red dashed line represents the true difference in means between the treatment and control distributions.\nAs the number of draws increases, you would expect the cumulative average to approach the true difference in means. This is because, with a larger sample size, the estimate of the difference in means becomes more accurate. If the cumulative average converges to the true difference in means, it indicates that the simulation is correctly capturing the underlying difference between the treatment and control groups.\n\n\nCentral Limit Theorem\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe histograms presented illustrate the Central Limit Theorem in action, highlighting how the distribution of the differences between the sample means increasingly approximates a normal distribution as the sample size grows. Given that zero is positioned near the center of these distributions, it suggests that there is no significant difference between the donation amounts of the treatment and control groups. This central positioning of zero within the distribution indicates that any observed difference is likely due to random sampling variability rather than a true effect of the treatment. Thus, the data provides no substantial evidence to suggest that the treatment influences donation amounts compared to the control."
  },
  {
    "objectID": "projects/MA/Untitled2.html",
    "href": "projects/MA/Untitled2.html",
    "title": "Joshua's Website",
    "section": "",
    "text": "import pandas as pd\ndf = pd.read_stata('karlan_list_2007.dta')\n\n\nimport matplotlib.pyplot as plt\n\n\nproportions = df.groupby('treatment')['gave'].mean().reset_index()\n\n# Create a bar plot\nplt.bar(proportions['treatment'], proportions['gave'], tick_label=['Control', 'Treatment'])\nplt.ylabel('Proportion of People Who Donated')\nplt.title('Proportion of Donations by Group')\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy import stats\nimport statsmodels.api as sm\ntreatment_donated = df[df['treatment'] == 1]['gave']\ncontrol_donated = df[df['treatment'] == 0]['gave']\n\n# Perform a t-test\nt_stat, p_value = stats.ttest_ind(treatment_donated, control_donated)\nprint(f\"T-test results: t-statistic = {t_stat}, p-value = {p_value}\")\n\n# Perform a linear regression\ndf['intercept'] = 1\nmodel = sm.OLS(df['gave'], df[['intercept', 'treatment']])\nresults = model.fit()\nprint(\"Linear regression results:\")\nprint(results.summary())\n\nT-test results: t-statistic = 3.101361000543946, p-value = 0.0019274025949016982\nLinear regression results:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Thu, 11 Apr 2024   Prob (F-statistic):            0.00193\nTime:                        11:55:08   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\ndf['intercept'] = 1\n\n# Define the model and fit it\nprobit_model = sm.Probit(df['gave'], df[['intercept', 'treatment']])\nprobit_results = probit_model.fit()\n\n# Print the summary of the regression results\nprint(probit_results.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Thu, 11 Apr 2024   Pseudo R-squ.:               0.0009783\nTime:                        12:04:20   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\ndf\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\nintercept\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n1\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n1\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n1\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n1\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n1\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n1\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n1\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n1\n\n\n\n\n50083 rows × 52 columns\n\n\n\n\n\nmatch21 = df[df['ratio'] == 2]['gave']\nmatch31 = df[df['ratio']== 3]['gave']\nmatch11 = df[df['ratio'] == 1]['gave']\n\nt_stat, p_value = stats.ttest_ind(match31, match21)\nprint(f\"T-test results: t-statistic = {t_stat}, p-value = {p_value}\")\nt_stat, p_value = stats.ttest_ind(match11, match31)\nprint(f\"T-test results: t-statistic = {t_stat}, p-value = {p_value}\")\nt_stat, p_value = stats.ttest_ind(match11, match21)\nprint(f\"T-test results: t-statistic = {t_stat}, p-value = {p_value}\")\n\nT-test results: t-statistic = 0.05011583793874515, p-value = 0.9600305283739325\nT-test results: t-statistic = -1.0150255853798622, p-value = 0.3101046637086672\nT-test results: t-statistic = -0.96504713432247, p-value = 0.33453168549723933\n\n\n\nprobit_model = sm.OLS(df['gave'], df[['intercept', 'ratio2', 'ratio3']])\nprobit_results = probit_model.fit()\nprint(probit_results.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     4.117\nDate:                Thu, 11 Apr 2024   Prob (F-statistic):             0.0163\nTime:                        12:16:26   Log-Likelihood:                 26629.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50080   BIC:                        -5.323e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.0190      0.001     22.306      0.000       0.017       0.021\nratio2         0.0036      0.002      2.269      0.023       0.000       0.007\nratio3         0.0037      0.002      2.332      0.020       0.001       0.007\n==============================================================================\nOmnibus:                    59815.856   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317637.927\nSkew:                           6.741   Prob(JB):                         0.00\nKurtosis:                      46.443   Cond. No.                         3.16\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
  },
  {
    "objectID": "hobbies/games/league.html",
    "href": "hobbies/games/league.html",
    "title": "League of Legends",
    "section": "",
    "text": "Here is a collection of my league clips\n\nAkali Aram Penta\n\n\n\nJhin Aram Penta\n\n\n\nViego Aram Penta\n\n\n\nYone Aram Penta\n\n\n\nViego Aram Penta 2"
  },
  {
    "objectID": "hobbies/games/basketball.html",
    "href": "hobbies/games/basketball.html",
    "title": "Joshua's Website",
    "section": "",
    "text": "Placeholder"
  },
  {
    "objectID": "hobbies.html",
    "href": "hobbies.html",
    "title": "Hobbies",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "hobbies.html#games",
    "href": "hobbies.html#games",
    "title": "Hobbies",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "hobbies.html#basketball",
    "href": "hobbies.html#basketball",
    "title": "Hobbies",
    "section": "Basketball",
    "text": "Basketball\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "hobbies/games/valorant.html",
    "href": "hobbies/games/valorant.html",
    "title": "Valorant",
    "section": "",
    "text": "Here is a collection of my valorant clips\n\nRaze Ace\n\n\n\nJett Outplay\n\n\n\nJett Ace\n\n\n\nKnifing Chamber"
  },
  {
    "objectID": "projects/MA/hw2_questions.html",
    "href": "projects/MA/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nThis is the first 5 rows of the data\n\n\nThe shape of the dataframe is: (1500, 4)\n\n\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n1\n0\nMidwest\n32.5\n0\n\n\n786\n3\nSouthwest\n37.5\n0\n\n\n348\n4\nNorthwest\n27.0\n1\n\n\n927\n3\nNortheast\n24.5\n0\n\n\n830\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\n\nThere are 1500 rows and 4 columns\n\n\n\n\n\n\n\n\n\n\n\n\npatents\nage\niscustomer\n\n\n\n\ncount\n1500.000000\n1500.000000\n1500.000000\n\n\nmean\n3.684667\n26.357667\n0.131333\n\n\nstd\n2.352500\n7.242528\n0.337877\n\n\nmin\n0.000000\n9.000000\n0.000000\n\n\n25%\n2.000000\n21.000000\n0.000000\n\n\n50%\n3.000000\n26.000000\n0.000000\n\n\n75%\n5.000000\n31.625000\n0.000000\n\n\nmax\n16.000000\n49.000000\n1.000000\n\n\n\n\n\n\n\n\n\n\n\n\npatents: Number of patents awarded over the last 5 years.\nregion: Regional location of the firm.\nage: Age of the firm since incorporation.\niscustomer: Indicates whether the firm uses Blueprinty’s software (1 = customer, 0 = not a customer)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmean_customers = df[df['iscustomer'] == 1]['patents'].mean()\nmean_non_customers = df[df['iscustomer'] == 0]['patents'].mean()\n(mean_customers, mean_non_customers)\n\n(4.091370558375634, 3.6231772831926325)\n\n\nThe mean number of patents for customers appears to be slightly higher at 4.09, while the mean number of patents for non-customers appear to be lower at 3.62.\n\n\n\nHowever, Blueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nTo investigate any systematic differences, below are plots that compare regions and ages by customer status\n\n\n\n\n\n\n\n\n\n\nmean_age_customers = data_customers['age'].mean()\nmean_age_non_customers = data_non_customers['age'].mean()\n(mean_age_customers, mean_age_non_customers)\n\n(24.1497461928934, 26.691481197237145)\n\n\nIt appears that the average age of customers are lower than the average age of non customers.\n\n\n\n\n\n\n\n\n\nThe distribution of customers and non-customers across regions is not uniform. Both histograms reveal differences in the concentration of customers versus non-customers in various regions, suggesting regional preferences or market penetration differences.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nThe likelihood function for a set of independent and identically distributed observations ( Y_1, Y_2, , Y_n ) from a Poisson distribution, where each ( Y_i ) represents the number of patents awarded to an engineering firm in a given period and follows a Poisson distribution with parameter ( ), is given by:\n\\[\nL(\\lambda | Y_1, Y_2, \\ldots, Y_n) = \\prod_{i=1}^n f(Y_i | \\lambda)\n\\]\nGiven the probability mass function of the Poisson distribution ( f(Y|) = e{-}Y/Y! ), the likelihood function can be written as:\n\\[\nL(\\lambda | Y_1, Y_2, \\ldots, Y_n) = \\prod_{i=1}^n \\left( \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!} \\right)\n\\]\nThis can be simplified to:\n\\[\nL(\\lambda | Y_1, Y_2, \\ldots, Y_n) = e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n Y_i} \\prod_{i=1}^n \\frac{1}{Y_i!}\n\\]\nHere, ( n ) is the total number of observations (engineering firms), ( {i=1}^n Y_i ) is the total number of patents awarded across all firms, and ( {i=1}^n ) is the product of the factorials of the counts of patents for each firm.\nThe log-likelihood function for the Poisson model, coded in a function of lambda and Y would look like the following:\n\nimport numpy as np\nfrom scipy.special import factorial\n\ndef poisson_loglikelihood(lambda_, Y):\n    if lambda_ &lt;= 0:\n        return -np.inf  # log-likelihood is negative infinity if lambda is non-positive\n    return np.sum(-lambda_ + Y * np.log(lambda_) - np.log(factorial(Y)))\n\nBelow I use the function above to plot lambda on the horizontal axis and the likelihood on the vertical axis for a range of lambdas, which I used the number of patents as the input.\n\n\n\n\n\n\n\n\n\nNow, I used scipy.optimize to find the MLE after optimizing the likelihood function\n\nfrom scipy.optimize import minimize\n\n# Define the negative log-likelihood function since we minimize in the optimization\ndef negative_loglikelihood(lambda_, Y):\n    if lambda_[0] &lt;= 0:\n        return np.inf  # Return infinity if lambda is non-positive\n    lambda_val = lambda_[0]\n    return -np.sum(-lambda_val + Y * np.log(lambda_val) - np.log(factorial(Y)))\n\n# Initial guess for lambda\ninitial_lambda = [1.0]\n\n# Using scipy's minimize function to find the MLE of lambda\nresult = minimize(negative_loglikelihood, initial_lambda, args=(patents_data,), method='L-BFGS-B', bounds=[(0, None)])\n\nprint(f\"MLE for lambda: {result['x'][0]}\")\n\nMLE for lambda: 3.6846667021660804\n\n\nThe optimization has successfully found the maximum likelihood estimate (MLE) of 𝜆 for the Poisson distribution based on the patent data. The MLE of 𝜆 is approximately 3.685. This indicates that the best estimate for the average number of patents awarded per engineering firm over the observed period, under the assumption of a Poisson distribution, is about 3.685 patents. ​\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nFirst, I need to update my previous log-likelihood function to reflect that:\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    linear = X @ beta\n    lambda_i = np.exp(np.clip(linear, None, 20))\n    \n    log_likelihood = np.sum(Y * np.log(lambda_i) - lambda_i - np.log(factorial(Y)))\n    return -log_likelihood  \n\nI then used the updated function to find the MLE vector and the Hessian of the Poisson model with covariates. I also printed out the coefficient and the standard effor for each variable.\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom scipy.linalg import inv\n\n\ndf['age_squared'] = df['age'] ** 2\n\nencoder = OneHotEncoder(drop='first')\nregion_encoded = encoder.fit_transform(df[['region']]).toarray()\n\n\nY = df['patents'].values\n\n\n\n\nfrom sklearn.preprocessing import StandardScaler\n\n# Scale the continuous variables\nscaler = StandardScaler()\nscaled_features = scaler.fit_transform(df[['age', 'age_squared']])\n\n# Construct the design matrix with scaled features\nX = np.hstack([np.ones((df.shape[0], 1)), scaled_features, df[['iscustomer']].values, region_encoded])\n\ninitial_beta = np.zeros(X.shape[1])\n\n# Run the optimizer with detailed logging\nresult = minimize(\n    fun=poisson_regression_loglikelihood,\n    x0=initial_beta,\n    args=(Y, X),\n    method='L-BFGS-B',\n    bounds=[(None, None)] * X.shape[1],\n    options={'disp': True}\n)\n\nhess_inv = result.hess_inv.todense()  # if using L-BFGS, convert to dense matrix\n\ndef neg_log_likelihood(beta, Y, X):\n    lambda_ = np.exp(np.dot(X, beta))\n    return np.sum(-Y * np.log(lambda_) + lambda_ + gammaln(Y + 1))\n\ndef grad_neg_log_likelihood(beta, Y, X):\n    lambda_ = np.exp(np.dot(X, beta))\n    grad = np.dot(X.T, lambda_ - Y)\n    return grad\n\ndef hessian_neg_log_likelihood(beta, Y, X):\n    lambda_ = np.exp(np.dot(X, beta))\n    diag_lambda = np.diag(lambda_)\n    hessian = np.dot(X.T, np.dot(diag_lambda, X))\n    return hessian\n\nhessian_matrix = hessian_neg_log_likelihood(result.x, Y, X)\n\ncovariance_matrix_from_hessian = inv(hessian_matrix)\n\nstandard_errors_from_hessian = np.sqrt(np.diag(covariance_matrix_from_hessian))\nvariables = ['Age', 'Age Squared', 'Customer Status', 'Region Northeast', 'Region Northwest', 'Region South', 'Region Southwest']\n# Print the coefficients and their standard errors\nfor v, coef, std_err in zip(variables, result.x, standard_errors_from_hessian):\n    print(f\"{v}| Coefficient: {coef:.4f}, Standard Error: {std_err:.4f}\")\n\nAge| Coefficient: 1.2155, Standard Error: 0.0364\nAge Squared| Coefficient: 1.0464, Standard Error: 0.1005\nCustomer Status| Coefficient: -1.1408, Standard Error: 0.1025\nRegion Northeast| Coefficient: 0.1182, Standard Error: 0.0389\nRegion Northwest| Coefficient: 0.0986, Standard Error: 0.0420\nRegion South| Coefficient: -0.0201, Standard Error: 0.0538\nRegion Southwest| Coefficient: 0.0572, Standard Error: 0.0527\n\n\nNow we try to replicate the coefficients and standard errors with statsmodels.GLM()\n\nimport statsmodels.api as sm\n\npoisson_model = sm.GLM(Y, X, family=sm.families.Poisson())\n\n# Fit the model\nresult = poisson_model.fit()\n\n# Display the summary\n# Extract standard errors\ncoefficients = result.params\nstandard_errors = result.bse\np_values = result.pvalues\nconf_int = pd.DataFrame(result.conf_int(), columns=['95% CI Lower', '95% CI Upper'])\n\nstats_table = pd.DataFrame({\n    'Coefficient': coefficients,\n    'Standard Error': standard_errors,\n    'P-value': p_values,\n    '95% CI Lower': conf_int['95% CI Lower'],\n    '95% CI Upper': conf_int['95% CI Upper']\n})\n\nprint(stats_table)\n\n   Coefficient  Standard Error        P-value  95% CI Lower  95% CI Upper\n0     1.215438        0.036426  4.023701e-244      1.144045      1.286831\n1     1.046460        0.100487   2.144106e-25      0.849508      1.243412\n2    -1.140845        0.102495   8.884562e-29     -1.341731     -0.939960\n3     0.118114        0.038920   2.407229e-03      0.041832      0.194397\n4     0.098596        0.042007   1.891865e-02      0.016264      0.180928\n5    -0.020094        0.053783   7.086909e-01     -0.125508      0.085319\n6     0.057172        0.052676   2.777636e-01     -0.046071      0.160414\n7     0.051347        0.047212   2.767834e-01     -0.041188      0.143882\n\n\nAs seen in the table, coefficients and standard errors perfectly match the ones above.\n\n\n\nThe coefficient for the variable (index 3) representing whether or not it is a customer of Blueprinty is positive (0.1181) and statistically significant, suggests that firms using Blueprinty’s software likely have a higher expected patent count. The coefficient further implies that using Blueprinty’s software increases the patent count likelihood by approximately exp(0.1181) ≈ 1.125, or 12.5%."
  },
  {
    "objectID": "projects/MA/hw2_questions.html#blueprinty-case-study",
    "href": "projects/MA/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nThis is the first 5 rows of the data\n\n\nThe shape of the dataframe is: (1500, 4)\n\n\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n1\n0\nMidwest\n32.5\n0\n\n\n786\n3\nSouthwest\n37.5\n0\n\n\n348\n4\nNorthwest\n27.0\n1\n\n\n927\n3\nNortheast\n24.5\n0\n\n\n830\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\n\nThere are 1500 rows and 4 columns\n\n\n\n\n\n\n\n\n\n\n\n\npatents\nage\niscustomer\n\n\n\n\ncount\n1500.000000\n1500.000000\n1500.000000\n\n\nmean\n3.684667\n26.357667\n0.131333\n\n\nstd\n2.352500\n7.242528\n0.337877\n\n\nmin\n0.000000\n9.000000\n0.000000\n\n\n25%\n2.000000\n21.000000\n0.000000\n\n\n50%\n3.000000\n26.000000\n0.000000\n\n\n75%\n5.000000\n31.625000\n0.000000\n\n\nmax\n16.000000\n49.000000\n1.000000\n\n\n\n\n\n\n\n\n\n\n\n\npatents: Number of patents awarded over the last 5 years.\nregion: Regional location of the firm.\nage: Age of the firm since incorporation.\niscustomer: Indicates whether the firm uses Blueprinty’s software (1 = customer, 0 = not a customer)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmean_customers = df[df['iscustomer'] == 1]['patents'].mean()\nmean_non_customers = df[df['iscustomer'] == 0]['patents'].mean()\n(mean_customers, mean_non_customers)\n\n(4.091370558375634, 3.6231772831926325)\n\n\nThe mean number of patents for customers appears to be slightly higher at 4.09, while the mean number of patents for non-customers appear to be lower at 3.62.\n\n\n\nHowever, Blueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nTo investigate any systematic differences, below are plots that compare regions and ages by customer status\n\n\n\n\n\n\n\n\n\n\nmean_age_customers = data_customers['age'].mean()\nmean_age_non_customers = data_non_customers['age'].mean()\n(mean_age_customers, mean_age_non_customers)\n\n(24.1497461928934, 26.691481197237145)\n\n\nIt appears that the average age of customers are lower than the average age of non customers.\n\n\n\n\n\n\n\n\n\nThe distribution of customers and non-customers across regions is not uniform. Both histograms reveal differences in the concentration of customers versus non-customers in various regions, suggesting regional preferences or market penetration differences.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nThe likelihood function for a set of independent and identically distributed observations ( Y_1, Y_2, , Y_n ) from a Poisson distribution, where each ( Y_i ) represents the number of patents awarded to an engineering firm in a given period and follows a Poisson distribution with parameter ( ), is given by:\n\\[\nL(\\lambda | Y_1, Y_2, \\ldots, Y_n) = \\prod_{i=1}^n f(Y_i | \\lambda)\n\\]\nGiven the probability mass function of the Poisson distribution ( f(Y|) = e{-}Y/Y! ), the likelihood function can be written as:\n\\[\nL(\\lambda | Y_1, Y_2, \\ldots, Y_n) = \\prod_{i=1}^n \\left( \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!} \\right)\n\\]\nThis can be simplified to:\n\\[\nL(\\lambda | Y_1, Y_2, \\ldots, Y_n) = e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n Y_i} \\prod_{i=1}^n \\frac{1}{Y_i!}\n\\]\nHere, ( n ) is the total number of observations (engineering firms), ( {i=1}^n Y_i ) is the total number of patents awarded across all firms, and ( {i=1}^n ) is the product of the factorials of the counts of patents for each firm.\nThe log-likelihood function for the Poisson model, coded in a function of lambda and Y would look like the following:\n\nimport numpy as np\nfrom scipy.special import factorial\n\ndef poisson_loglikelihood(lambda_, Y):\n    if lambda_ &lt;= 0:\n        return -np.inf  # log-likelihood is negative infinity if lambda is non-positive\n    return np.sum(-lambda_ + Y * np.log(lambda_) - np.log(factorial(Y)))\n\nBelow I use the function above to plot lambda on the horizontal axis and the likelihood on the vertical axis for a range of lambdas, which I used the number of patents as the input.\n\n\n\n\n\n\n\n\n\nNow, I used scipy.optimize to find the MLE after optimizing the likelihood function\n\nfrom scipy.optimize import minimize\n\n# Define the negative log-likelihood function since we minimize in the optimization\ndef negative_loglikelihood(lambda_, Y):\n    if lambda_[0] &lt;= 0:\n        return np.inf  # Return infinity if lambda is non-positive\n    lambda_val = lambda_[0]\n    return -np.sum(-lambda_val + Y * np.log(lambda_val) - np.log(factorial(Y)))\n\n# Initial guess for lambda\ninitial_lambda = [1.0]\n\n# Using scipy's minimize function to find the MLE of lambda\nresult = minimize(negative_loglikelihood, initial_lambda, args=(patents_data,), method='L-BFGS-B', bounds=[(0, None)])\n\nprint(f\"MLE for lambda: {result['x'][0]}\")\n\nMLE for lambda: 3.6846667021660804\n\n\nThe optimization has successfully found the maximum likelihood estimate (MLE) of 𝜆 for the Poisson distribution based on the patent data. The MLE of 𝜆 is approximately 3.685. This indicates that the best estimate for the average number of patents awarded per engineering firm over the observed period, under the assumption of a Poisson distribution, is about 3.685 patents. ​\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nFirst, I need to update my previous log-likelihood function to reflect that:\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    linear = X @ beta\n    lambda_i = np.exp(np.clip(linear, None, 20))\n    \n    log_likelihood = np.sum(Y * np.log(lambda_i) - lambda_i - np.log(factorial(Y)))\n    return -log_likelihood  \n\nI then used the updated function to find the MLE vector and the Hessian of the Poisson model with covariates. I also printed out the coefficient and the standard effor for each variable.\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom scipy.linalg import inv\n\n\ndf['age_squared'] = df['age'] ** 2\n\nencoder = OneHotEncoder(drop='first')\nregion_encoded = encoder.fit_transform(df[['region']]).toarray()\n\n\nY = df['patents'].values\n\n\n\n\nfrom sklearn.preprocessing import StandardScaler\n\n# Scale the continuous variables\nscaler = StandardScaler()\nscaled_features = scaler.fit_transform(df[['age', 'age_squared']])\n\n# Construct the design matrix with scaled features\nX = np.hstack([np.ones((df.shape[0], 1)), scaled_features, df[['iscustomer']].values, region_encoded])\n\ninitial_beta = np.zeros(X.shape[1])\n\n# Run the optimizer with detailed logging\nresult = minimize(\n    fun=poisson_regression_loglikelihood,\n    x0=initial_beta,\n    args=(Y, X),\n    method='L-BFGS-B',\n    bounds=[(None, None)] * X.shape[1],\n    options={'disp': True}\n)\n\nhess_inv = result.hess_inv.todense()  # if using L-BFGS, convert to dense matrix\n\ndef neg_log_likelihood(beta, Y, X):\n    lambda_ = np.exp(np.dot(X, beta))\n    return np.sum(-Y * np.log(lambda_) + lambda_ + gammaln(Y + 1))\n\ndef grad_neg_log_likelihood(beta, Y, X):\n    lambda_ = np.exp(np.dot(X, beta))\n    grad = np.dot(X.T, lambda_ - Y)\n    return grad\n\ndef hessian_neg_log_likelihood(beta, Y, X):\n    lambda_ = np.exp(np.dot(X, beta))\n    diag_lambda = np.diag(lambda_)\n    hessian = np.dot(X.T, np.dot(diag_lambda, X))\n    return hessian\n\nhessian_matrix = hessian_neg_log_likelihood(result.x, Y, X)\n\ncovariance_matrix_from_hessian = inv(hessian_matrix)\n\nstandard_errors_from_hessian = np.sqrt(np.diag(covariance_matrix_from_hessian))\nvariables = ['Age', 'Age Squared', 'Customer Status', 'Region Northeast', 'Region Northwest', 'Region South', 'Region Southwest']\n# Print the coefficients and their standard errors\nfor v, coef, std_err in zip(variables, result.x, standard_errors_from_hessian):\n    print(f\"{v}| Coefficient: {coef:.4f}, Standard Error: {std_err:.4f}\")\n\nAge| Coefficient: 1.2155, Standard Error: 0.0364\nAge Squared| Coefficient: 1.0464, Standard Error: 0.1005\nCustomer Status| Coefficient: -1.1408, Standard Error: 0.1025\nRegion Northeast| Coefficient: 0.1182, Standard Error: 0.0389\nRegion Northwest| Coefficient: 0.0986, Standard Error: 0.0420\nRegion South| Coefficient: -0.0201, Standard Error: 0.0538\nRegion Southwest| Coefficient: 0.0572, Standard Error: 0.0527\n\n\nNow we try to replicate the coefficients and standard errors with statsmodels.GLM()\n\nimport statsmodels.api as sm\n\npoisson_model = sm.GLM(Y, X, family=sm.families.Poisson())\n\n# Fit the model\nresult = poisson_model.fit()\n\n# Display the summary\n# Extract standard errors\ncoefficients = result.params\nstandard_errors = result.bse\np_values = result.pvalues\nconf_int = pd.DataFrame(result.conf_int(), columns=['95% CI Lower', '95% CI Upper'])\n\nstats_table = pd.DataFrame({\n    'Coefficient': coefficients,\n    'Standard Error': standard_errors,\n    'P-value': p_values,\n    '95% CI Lower': conf_int['95% CI Lower'],\n    '95% CI Upper': conf_int['95% CI Upper']\n})\n\nprint(stats_table)\n\n   Coefficient  Standard Error        P-value  95% CI Lower  95% CI Upper\n0     1.215438        0.036426  4.023701e-244      1.144045      1.286831\n1     1.046460        0.100487   2.144106e-25      0.849508      1.243412\n2    -1.140845        0.102495   8.884562e-29     -1.341731     -0.939960\n3     0.118114        0.038920   2.407229e-03      0.041832      0.194397\n4     0.098596        0.042007   1.891865e-02      0.016264      0.180928\n5    -0.020094        0.053783   7.086909e-01     -0.125508      0.085319\n6     0.057172        0.052676   2.777636e-01     -0.046071      0.160414\n7     0.051347        0.047212   2.767834e-01     -0.041188      0.143882\n\n\nAs seen in the table, coefficients and standard errors perfectly match the ones above.\n\n\n\nThe coefficient for the variable (index 3) representing whether or not it is a customer of Blueprinty is positive (0.1181) and statistically significant, suggests that firms using Blueprinty’s software likely have a higher expected patent count. The coefficient further implies that using Blueprinty’s software increases the patent count likelihood by approximately exp(0.1181) ≈ 1.125, or 12.5%."
  },
  {
    "objectID": "projects/MA/hw2_questions.html#airbnb-case-study",
    "href": "projects/MA/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\ntodo: Assume the number of reviews is a good proxy for the number of bookings. Perform some exploratory data analysis to get a feel for the data, handle or drop observations with missing values on relevant variables, build one or more models (e.g., a poisson regression model for the number of bookings as proxied by the number of reviews), and interpret model coefficients to describe variation in the number of reviews as a function of the variables provided.\n\n\nLoading Data\n\n\n(40628, 13)\n\n\n\n\n\n\n\n\n\n\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\n1\n2515\n3130\n4/2/2017\n9/6/2008\nPrivate room\n1.0\n1.0\n59\n150\n9.0\n9.0\n9.0\nf\n\n\n2\n2595\n3127\n4/2/2017\n9/9/2008\nEntire home/apt\n1.0\n0.0\n230\n20\n9.0\n10.0\n9.0\nf\n\n\n3\n3647\n3050\n4/2/2017\n11/25/2008\nPrivate room\n1.0\n1.0\n150\n0\nNaN\nNaN\nNaN\nf\n\n\n4\n3831\n3038\n4/2/2017\n12/7/2008\nEntire home/apt\n1.0\n1.0\n89\n116\n9.0\n9.0\n9.0\nf\n\n\n5\n4611\n3012\n4/2/2017\n1/2/2009\nPrivate room\nNaN\n1.0\n39\n93\n9.0\n8.0\n9.0\nt\n\n\n\n\n\n\n\n\nThe dataframe has 40628 rows and 13 columns, I’ve also shown the first 5 rows of the dataframe\n\n\nData Statistics\n\n\n\n\n\n\n\n\n\n\nid\ndays\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\n\n\n\n\ncount\n4.062800e+04\n40628.000000\n40468.000000\n40552.000000\n40628.000000\n40628.000000\n30433.000000\n30374.000000\n30372.000000\n\n\nmean\n9.698889e+06\n1102.368219\n1.124592\n1.147046\n144.760732\n15.904426\n9.198370\n9.413544\n9.331522\n\n\nstd\n5.460166e+06\n1383.269358\n0.385884\n0.691746\n210.657597\n29.246009\n1.119935\n0.844949\n0.902966\n\n\nmin\n2.515000e+03\n1.000000\n0.000000\n0.000000\n10.000000\n0.000000\n2.000000\n2.000000\n2.000000\n\n\n25%\n4.889868e+06\n542.000000\n1.000000\n1.000000\n70.000000\n1.000000\n9.000000\n9.000000\n9.000000\n\n\n50%\n9.862878e+06\n996.000000\n1.000000\n1.000000\n100.000000\n4.000000\n10.000000\n10.000000\n10.000000\n\n\n75%\n1.466789e+07\n1535.000000\n1.000000\n1.000000\n170.000000\n17.000000\n10.000000\n10.000000\n10.000000\n\n\nmax\n1.800967e+07\n42828.000000\n8.000000\n10.000000\n10000.000000\n421.000000\n10.000000\n10.000000\n10.000000\n\n\n\n\n\n\n\n\n\n\nData Cleaning\n\ndf.isna().sum()\n\nid                               0\ndays                             0\nlast_scraped                     0\nhost_since                      35\nroom_type                        0\nbathrooms                      160\nbedrooms                        76\nprice                            0\nnumber_of_reviews                0\nreview_scores_cleanliness    10195\nreview_scores_location       10254\nreview_scores_value          10256\ninstant_bookable                 0\ndtype: int64\n\n\nThe dataset appears to contain several columns with null values.\nSince the dataset is large enough, I’ve decided to drop all null values to see if the remaining dataset is still large enough to proceed.\n\ndf_1 = df.dropna()\ndf_1.shape\n\n(30140, 13)\n\n\nWith over 30000 rows, I’ve decided that the dataset is large enough to continue.\n\n\nUpdated Data Statistics\n\n\n\n\n\n\n\n\n\n\nid\ndays\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\n\n\n\n\ncount\n3.014000e+04\n30140.000000\n30140.000000\n30140.000000\n30140.000000\n30140.000000\n30140.000000\n30140.000000\n30140.000000\n\n\nmean\n8.978322e+06\n1112.048275\n1.122213\n1.151460\n140.211546\n21.168115\n9.201758\n9.415428\n9.334041\n\n\nstd\n5.376960e+06\n644.430782\n0.385031\n0.699039\n188.437967\n32.004711\n1.114472\n0.843181\n0.900595\n\n\nmin\n2.515000e+03\n7.000000\n0.000000\n0.000000\n10.000000\n1.000000\n2.000000\n2.000000\n2.000000\n\n\n25%\n4.276596e+06\n584.000000\n1.000000\n1.000000\n70.000000\n3.000000\n9.000000\n9.000000\n9.000000\n\n\n50%\n9.149773e+06\n1040.000000\n1.000000\n1.000000\n103.000000\n8.000000\n10.000000\n10.000000\n10.000000\n\n\n75%\n1.391476e+07\n1591.000000\n1.000000\n1.000000\n169.000000\n26.000000\n10.000000\n10.000000\n10.000000\n\n\nmax\n1.797369e+07\n3317.000000\n6.000000\n10.000000\n10000.000000\n421.000000\n10.000000\n10.000000\n10.000000\n\n\n\n\n\n\n\n\n\n\nEDA\n\n\n\n\n\n\n\n\n\nThe distribution of the numbers of reviews is heavility skewed to the right, indicating that most listings have relatively few reviews (&lt;100).\nThere also does not seem to have a clean linear relationship between price and the number of reviews. Although houses with more reviews does tend to have lower price, likely because people tend to want to book cheaper houses.\nAdditionally, there does not appear to be a linear relationship between the number of reviews and the number of days listed. Although as the numbers of days listed increases, the number of days also likely increases.\nFinally, houses with around 2-3 bathrooms receive the most reviews.\n\n\nPoisson Model\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\ndf_1['room_type'] = df_1['room_type'].astype('category')\ndf_1['instant_bookable'] = df_1['instant_bookable'].astype('category').cat.codes\n\nformula = 'number_of_reviews ~ room_type + price + review_scores_cleanliness + review_scores_location + review_scores_value + instant_bookable + days + bathrooms + bedrooms'\npoisson_model = smf.glm(formula=formula, data=df_1, family=sm.families.Poisson()).fit()\n\n# Output model summary\nmodel_params = poisson_model.summary2().tables[1][['Coef.', 'Std.Err.', 'z', 'P&gt;|z|']]\nmodel_params\n\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nz\nP&gt;|z|\n\n\n\n\nIntercept\n2.942697\n0.016633\n176.919813\n0.000000e+00\n\n\nroom_type[T.Private room]\n0.019233\n0.002738\n7.024594\n2.146901e-12\n\n\nroom_type[T.Shared room]\n-0.115193\n0.008650\n-13.317770\n1.824774e-40\n\n\nprice\n-0.000043\n0.000008\n-5.199251\n2.000937e-07\n\n\nreview_scores_cleanliness\n0.110978\n0.001517\n73.158720\n0.000000e+00\n\n\nreview_scores_location\n-0.081481\n0.001617\n-50.402764\n0.000000e+00\n\n\nreview_scores_value\n-0.091055\n0.001847\n-49.310566\n0.000000e+00\n\n\ninstant_bookable\n0.459104\n0.002919\n157.293238\n0.000000e+00\n\n\ndays\n0.000522\n0.000002\n280.429721\n0.000000e+00\n\n\nbathrooms\n-0.113444\n0.003773\n-30.066678\n1.321761e-198\n\n\nbedrooms\n0.075659\n0.002033\n37.214455\n3.983758e-303\n\n\n\n\n\n\n\n\n\n\nAnalysis Summary\nThe analysis reveals that compared to entire homes/apartments, which serve as the base category, private rooms actually have a slight positive effect on the number of reviews (coefficient = +0.019). This suggests that private rooms might receive slightly more bookings compared to entire homes/apartments. Conversely, shared rooms have a substantial negative impact on the number of reviews (coefficient = -0.115), indicating significantly fewer bookings for shared accommodations.\nThe coefficients for review scores indicate varied effects on booking rates. High cleanliness scores are strongly associated with an increase in bookings (coefficient = +0.111), highlighting the importance guests place on cleanliness. Interestingly, better scores for location (coefficient = -0.081) and value (coefficient = -0.091) are associated with fewer bookings. This counterintuitive result may suggest that higher expectations for these aspects could negatively impact guest satisfaction or reflect a trade-off guests are making with other variables such as price.\nThe model outputs indicate that the number of bathrooms negatively affects the number of reviews (coefficient = -0.113). This could suggest that listings with more bathrooms may not necessarily increase the likelihood of bookings. This could be due to higher associated costs or perhaps the type of listings that typically feature multiple bathrooms.\nConversely, an increase in the number of bedrooms has a positive effect on the number of reviews (coefficient = +0.076), indicating that listings with more bedrooms tend to be more popular or accommodating for larger groups, thus potentially receiving more bookings.\nThe coefficient for days listed (days) is positive (coefficient = +0.000522), showing that the longer a listing has been on the platform, the more reviews it accumulates. This trend likely reflects a cumulative effect where older listings have had more time to accumulate reviews, thus suggesting a gradual build-up of bookings over time.\nMost importantly, listings that are instantly bookable tend to have more bookings, which makes sense as it allows guests to book without waiting for host approval, making the process quicker and more convenient."
  }
]