---
title: "Multinomial Logit Examples"
author: "Joshua Chen"
date: today
editor_options: 
  chunk_output_type: console
jupyter: python3
---


This assignment uses uses the MNL model to analyze (1) yogurt purchase data made by consumers at a retail location, and (2) conjoint data about consumer preferences for minivans.


## 1. Estimating Yogurt Preferences

### Likelihood for the Multi-nomial Logit (MNL) Model

Suppose we have $i=1,\ldots,n$ consumers who each select exactly one product $j$ from a set of $J$ products. The outcome variable is the identity of the product chosen $y_i \in \{1, \ldots, J\}$ or equivalently a vector of $J-1$ zeros and $1$ one, where the $1$ indicates the selected product. For example, if the third product was chosen out of 4 products, then either $y=3$ or $y=(0,0,1,0)$ depending on how we want to represent it. Suppose also that we have a vector of data on each product $x_j$ (eg, size, price, etc.). 

We model the consumer's decision as the selection of the product that provides the most utility, and we'll specify the utility function as a linear function of the product characteristics:

$$ U_{ij} = x_j'\beta + \epsilon_{ij} $$

where $\epsilon_{ij}$ is an i.i.d. extreme value error term. 

The choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer $i$ chooses product $j$:

$$ \mathbb{P}_i(j) = \frac{e^{x_j'\beta}}{\sum_{k=1}^Je^{x_k'\beta}} $$

For example, if there are 4 products, the probability that consumer $i$ chooses product 3 is:

$$ \mathbb{P}_i(3) = \frac{e^{x_3'\beta}}{e^{x_1'\beta} + e^{x_2'\beta} + e^{x_3'\beta} + e^{x_4'\beta}} $$

A clever way to write the individual likelihood function for consumer $i$ is the product of the $J$ probabilities, each raised to the power of an indicator variable ($\delta_{ij}$) that indicates the chosen product:

$$ L_i(\beta) = \prod_{j=1}^J \mathbb{P}_i(j)^{\delta_{ij}} = \mathbb{P}_i(1)^{\delta_{i1}} \times \ldots \times \mathbb{P}_i(J)^{\delta_{iJ}}$$

Notice that if the consumer selected product $j=3$, then $\delta_{i3}=1$ while $\delta_{i1}=\delta_{i2}=\delta_{i4}=0$ and the likelihood is:

$$ L_i(\beta) = \mathbb{P}_i(1)^0 \times \mathbb{P}_i(2)^0 \times \mathbb{P}_i(3)^1 \times \mathbb{P}_i(4)^0 = \mathbb{P}_i(3) = \frac{e^{x_3'\beta}}{\sum_{k=1}^Je^{x_k'\beta}} $$

The joint likelihood (across all consumers) is the product of the $n$ individual likelihoods:

$$ L_n(\beta) = \prod_{i=1}^n L_i(\beta) = \prod_{i=1}^n \prod_{j=1}^J \mathbb{P}_i(j)^{\delta_{ij}} $$

And the joint log-likelihood function is:

$$ \ell_n(\beta) = \sum_{i=1}^n \sum_{j=1}^J \delta_{ij} \log(\mathbb{P}_i(j)) $$


### Yogurt Dataset

We will use the `yogurt_data` dataset, which provides anonymized consumer identifiers (`id`), a vector indicating the chosen product (`y1`:`y4`), a vector indicating if any products were "featured" in the store as a form of advertising (`f1`:`f4`), and the products' prices (`p1`:`p4`). For example, consumer 1 purchased yogurt 4 at a price of 0.079/oz and none of the yogurts were featured/advertised at the time of consumer 1's purchase.  Consumers 2 through 7 each bought yogurt 2, etc.
```{python}
#| echo: false
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt
import seaborn as sns
import os 
from warnings import filterwarnings
filterwarnings('ignore')
from itables import show
from scipy.optimize import minimize
```
::::{.callout-note collapse="true"}
### Raw Dataset
```{python}
#| echo: false
yogurt_data = pd.read_csv("yogurt_data.csv")
show(yogurt_data)
```
::::
Let the vector of product features include brand dummy variables for yogurts 1-3 (we'll omit a dummy for product 4 to avoid multi-collinearity), a dummy variable to indicate if a yogurt was featured, and a continuous variable for the yogurts' prices:  

$$
x_j' = [\mathbf{1}(\text{Yogurt 1}), \mathbf{1}(\text{Yogurt 2}), \mathbf{1}(\text{Yogurt 3}), X_f, X_p]
$$

The "hard part" of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer $i$, covariate $k$, and product $j$) instead of the typical 2 dimensions for cross-sectional regression models (consumer $i$ and covariate $k$). 

What we would like to do is reorganize the data from a "wide" shape with $n$ rows and multiple columns for each covariate, to a "long" shape with $n \times J$ rows and a single column for each covariate.  As part of this re-organization, we'll add binary variables to indicate the first 3 products; the variables for featured and price are included in the dataset and simply need to be "pivoted" or "melted" from wide to long.  

::::{.callout-note collapse="true"}
### Melting the Data
```{python}
# Melt the data to long format
yogurt_long = pd.melt(yogurt_data, id_vars=['id'], value_vars=['y1', 'y2', 'y3', 'y4'],var_name='product', value_name='chosen')
# Extract product number
yogurt_long['product'] = yogurt_long['product'].str.extract('(\d)').astype(int)
# Melt the features to long format
features = pd.melt(yogurt_data, id_vars=['id'], value_vars=['f1', 'f2', 'f3', 'f4'], var_name='f_product', value_name='featured')
# Extract product number
features['f_product'] = features['f_product'].str.extract('(\d)').astype(int)
# Melt the prices to long format
prices = pd.melt(yogurt_data, id_vars=['id'], value_vars=['p1', 'p2', 'p3', 'p4'], var_name='p_product', value_name='price')
# Extract product number
prices['p_product'] = prices['p_product'].str.extract('(\d)').astype(int)
# Merge the data togehter
yogurt_long = yogurt_long.merge(features, left_on=['id', 'product'], right_on=['id', 'f_product'])
yogurt_long = yogurt_long.merge(prices, left_on=['id', 'product'], right_on=['id', 'p_product'])
yogurt_long.drop(columns=['f_product', 'p_product'], inplace=True)
# Create dummy variables for products 1, 2, and 3
yogurt_long['yogurt 1'] = (yogurt_long['product'] == 1).astype(int)
yogurt_long['yogurt 2'] = (yogurt_long['product'] == 2).astype(int)
yogurt_long['yogurt 3'] = (yogurt_long['product'] == 3).astype(int)
```
::::

::::{.callout-note collapse="true"}
### Cleaned Dataset
```{python}
#| echo: false
show(yogurt_long)
```
::::
### Estimation

The log likelihood function that I will use it shown below: 

```{python}
def log_likelihood(beta, data):
    """
    Calculates the log-likelihood of the MNL model.

    Parameters:
    beta: Coefficients β1, β2, β3, βf, βp.
    data: The reshaped long format dataframe with columns ['id', 'product', 'chosen', 'featured', 'price', 'yogurt 1', 'yogurt 2', 'yogurt 3'].

    Returns:
    float: The log-likelihood value.
    """
    beta1, beta2, beta3, beta_f, beta_p = beta
    data['utility'] = (beta1 * data['yogurt 1'] + 
                       beta2 * data['yogurt 2'] + 
                       beta3 * data['yogurt 3'] + 
                       beta_f * data['featured'] + 
                       beta_p * data['price'])
    data['exp_utility'] = np.exp(data['utility'])
    data['sum_exp_utility'] = data.groupby('id')['exp_utility'].transform('sum')
    data['probability'] = data['exp_utility'] / data['sum_exp_utility']
    data['log_likelihood'] = data['chosen'] * np.log(data['probability'])
    return -data['log_likelihood'].sum()
```

With the function defined, I then used scipy.optimize from Python to find the beta values for the 5 parameters. First, I initilized all the guesses as zero, then I used the minimize() fucntion from scipy.optimize to find the beta values. The values are shown below.
```{python}
initial = [0,0,0,0,0]
result = minimize(log_likelihood, initial, args = (yogurt_long), method = 'BFGS')
beta_1, beta_2, beta_3, beta_f, beta_p = result.x
```
```{python}
#| echo: false
print('Estimated parameters:')
print('beta_1:', beta_1)
print('beta_2:', beta_2)
print('beta_3:', beta_3)
print('beta_f:', beta_f)
print('beta_p:', beta_p)
```

### Discussion

From the beta intercept values, we learned that:

1. Yogust 1 is the most preferred as ($\beta_1$) has the largest positive value
2. Yogurt 2 is also second most preferred as ($\beta_2$) is also positive. However, it is less preferred compared to Yogurt 1
3. Yogurt 3 is the least preferred, as suggested by the negative ($\beta_3$)
4. Yogurt 4 is third preferred. As it is the base comparison and there are 2 yogurts with positive coefficients and 1 yogurt with negative coefficient, making yogurt 4 the third preferred
4. ($\beta_f$) having a positive value of 0.487 indicates that featuring a yogurt increases its utility and thus its chance of being selected
5. ($\beta_p$) having a large negative value of 37.058 indicates higher prices reduces the chance of a yogurt being selected

The estimated price coefficient ($\beta_p$) can be used as a dollar-per-util conversion factor. Using this conversion factor, I then calculated the dollar benefit between the most preferred yogurt (Yogurt 1) and the least preferred yogurt (yogurt 3). The per-unit monetary measure of the brand value and the calculation is shown below.
```{python}
conversion_factor = -1 / beta_p
utility_difference = beta_1 - beta_3
monetary_value = utility_difference * conversion_factor
monetary_value
```

The monetary benefit between the most preferred yogurt (Yogurt 1) and the least preferred yogurt (yogurt 3) is approximately $0.12 per unit, meaning that customers value Yogurt 1 about $0.12 more than Yogurt 3.

In addion, with the MNL model, I was able to simulate the counterfactuals (eg, what if the price of yogurt 1 was $0.10/oz instead of $0.08/oz). 

The first step in achieving this is to define a function that can predit market shares. The function is shown below:

```{python}
def predict_market_shares(beta, data):
    """
    Predict market shares using the estimated beta coefficients.

    Parameters:
    beta: Coefficients β1, β2, β3, βf, βp.
    data: The reshaped long format dataframe with columns ['id', 'product', 'chosen', 'featured', 'price', 'yogurt 1', 'yogurt 2', 'yogurt 3'].

    Returns:
    DataFrame: The predicted market shares for each product.
    """
    data['utility'] = (beta[0] * data['yogurt 1'] + 
                       beta[1] * data['yogurt 2'] + 
                       beta[2] * data['yogurt 3'] + 
                       beta[3] * data['featured'] + 
                       beta[4] * data['price'])
    data['exp_utility'] = np.exp(data['utility'])
    data['sum_exp_utility'] = data.groupby('id')['exp_utility'].transform('sum')
    data['probability'] = data['exp_utility'] / data['sum_exp_utility']
    market_shares = data.groupby('product')['probability'].mean().reset_index()
    market_shares.columns = ['product', 'market_share']
    return market_shares
```

Running the predict market shares function, the original market shares are:
```{python}
original_market_shares = predict_market_shares(result.x, yogurt_long)
original_market_shares
```

and the new market shares after price increase are:

```{python}
yogurt_long.loc[yogurt_long['product'] == 1, 'price'] += 0.10
new_market_shares = predict_market_shares(result.x, yogurt_long)
new_market_shares
```

Increasing the price of Yogurt 1 by $0.10 significantly decreased its market share from 34% to 2%, leading to an increase in market share for the other yogurts. This indicates that Yogurt 1 is highly price-sensitive, suggesting that customers perceive it as less differentiated or less valuable compared to other options, making them more likely to switch to alternatives when its price rises.




## 2. Estimating Minivan Preferences


### Data

::::{.callout-note collapse="true"}
#### Conjoint Dataset
```{python}
#| echo: false
conjoint_data = pd.read_csv("rintro-chapter13conjoint.csv")
show(conjoint_data)
```
::::
#### Variables
- `resp.id`: Respondent identifier
- `ques`: task number
- `alt`: Alternative number 
- `carpool`: Carpool option (yes/no)
- `seat`: Number of seats (6, 7, 8)
- `cargo`: Cargo space (2ft, 3ft)
- `eng`: Engine type (gas, hybrid, electric)
- `price`: Price in thousands of dollars
- `choice`: 1 if alternative was chosen 0 if not

The attributes (levels) were number of seats (6,7,8), cargo space (2ft, 3ft), engine type (gas, hybrid, electric), and price (in thousands of dollars).

```{python}
num_resp = conjoint_data['resp.id'].nunique()
num_choice = conjoint_data['ques'].nunique()
num_alt = conjoint_data['alt'].nunique()
```
```{python}
#| echo: false
print(f"Number of respondents: {num_resp}")
print(f"Number of choice tasks per respondent: {num_choice}")
print(f"Number of alternatives per choice task: {num_alt}")
```

### Model

To estimate an MNL moel, I omitted the following levels to avoid multicollinearity:
1. 6 in `seat`
2. 2ft in `cargo`
3. Gas in `eng`

The varialbes in the model are:
1. `seat_7`: Dummy varialbe for 7 seats
2. `seat_8`: Dummy varialbe for 8 seats
3. `cargo_3ft`: Dummy varialbe for 3ft cargo space
4. `eng_hyb`: Dummy variable for hybrid engine
5. `eng_elec`: Dummy variable for electric engine
6. `price`: price in thousands of dollars

```{python}
#| echo: false
conjoint_data['seat_7'] = (conjoint_data['seat'] == 7).astype(int)
conjoint_data['seat_8'] = (conjoint_data['seat'] == 8).astype(int)
conjoint_data['cargo_3ft'] = (conjoint_data['cargo'] == '3ft').astype(int)
conjoint_data['eng_hyb'] = (conjoint_data['eng'] == 'hyb').astype(int)
conjoint_data['eng_elec'] = (conjoint_data['eng'] == 'elec').astype(int)
```

I will be running the model with the slightly modified log_likelihood function from the Yogurt report. 

The function is shown below
```{python}
def log_likelihood(beta, data):
    """
    Calculates the log-likelihood of the MNL model.

    Parameters:
    beta: Coefficients β_seat_7, β_seat_8, β_cargo_3ft, β_eng_hyb, β_eng_elec, β_price
    data: The conjoint data with the variables listed above
    
    Returns:
    float: The log-likelihood value.
    """
    beta_seat_7, beta_seat_8, beta_cargo_3ft, beta_eng_hyb, beta_eng_elec, beta_price = beta
    data['utility'] = (beta_seat_7 * data['seat_7'] +
                       beta_seat_8 * data['seat_8'] +
                       beta_cargo_3ft * data['cargo_3ft'] +
                       beta_eng_hyb * data['eng_hyb'] +
                       beta_eng_elec * data['eng_elec'] +
                       beta_price * data['price'])
    data['exp_utility'] = np.exp(data['utility'])
    data['sum_exp_utility'] = data.groupby(['resp.id', 'ques'])['exp_utility'].transform('sum')
    data['probability'] = data['exp_utility'] / data['sum_exp_utility']
    data['log_likelihood'] = data['choice'] * np.log(data['probability'])
    return -data['log_likelihood'].sum()
```

I then used scipy.optimize from Python to find the beta values for the 6 parameters. First, I initilized all the guesses as zero, then I used the minimize() fucntion from scipy.optimize to find the beta values. The values are shown below.

```{python}
initial = np.zeros(6)
result = minimize(log_likelihood, initial, args=(conjoint_data), method='BFGS')
estimated_beta_conjoint = result.x
```

```{python}
beta_seat_7 = estimated_beta_conjoint[0]
beta_seat_8 = estimated_beta_conjoint[1]
beta_cargo_3ft = estimated_beta_conjoint[2]
beta_hybrid_engine = estimated_beta_conjoint[3]
beta_electric_engine = estimated_beta_conjoint[4]
beta_price = estimated_beta_conjoint[5]

print_statement = f"""- beta seat 7: {beta_seat_7}
- beta seat 8: {beta_seat_8}
- beta cargo 3ft: {beta_cargo_3ft}
- beta hybrid engine: {beta_hybrid_engine}
- beta electric engine: {beta_electric_engine}
- beta price: {beta_price}"""

print(print_statement)
```
### Results

#### Coefficient Interpretation
1. Seats
  - 7 seats: The negative coefficient suggests that 7 seats are less preferred compared to 6 seats
  - 8 seats: The negative coefficient suggests that 8 seats are less preferred compared to 6 seats, but not as less preferred as 7 seats
  - 6 Seats is the most preferred, followed by 8 seats, and 7 seats is the least preferred
2. Cargo Space
  - 3ft cargo: The positive coefficient suggests that 3ft cargo space is preferred over 2 ft cargo space
  - 3ft cargo space is most preferred, 2ft cargo space is least preferred
3. Engine
  - Hybrid Engine: The negative coefficient suggests that hybrid engines are less preferred compared to gas engines.
  - Electric Engine: The negative coefficient suggests that electric engines are also less preferred compared to gas enginges, and also less preferred compared to hybrid engine as the coefficient is larger in magnitude.
  - Gas engine is the most preferred, followed by hybrid engine, and electric engine is the least preferred
4. Price
  - The negative coefficient indicates that higher prices decrease the utility of the minivan, meaning that it is less likely to be selected
#### Dollar-Per-Util Calculation

I then used the price coefficent as a dollar-per-util conversion factor and calcualted the value of 3ft cargo space compared to 2ft cargo space. The calculation and value are shown below:
```{python}
conversion_factor = -1 / estimated_beta_conjoint[5]
utility_difference = estimated_beta_conjoint[2]
value = utility_difference * conversion_factor * 1000
```

```{python}
#| echo: false

print(f'The monetary value of having 3ft of cargo space compared to 2ft of cargo space is approximately ${value}. This means that, on average, consumers value the additional 1ft of cargo space at ${value}')

```

### Market Share Prediction
Assuming the market consists of the following 6 minivans, I used the model above (the beta coefficients) to predict the market shares of these 6 minivans.

| Minivan | Seats | Cargo | Engine | Price |
|---------|-------|-------|--------|-------|
| A       | 7     | 2     | Hyb    | 30    |
| B       | 6     | 2     | Gas    | 30    |
| C       | 8     | 2     | Gas    | 30    |
| D       | 7     | 3     | Gas    | 40    |
| E       | 6     | 2     | Elec   | 40    |
| F       | 7     | 2     | Hyb    | 35    |

::::{.callout-note collapse="true"}
### Calculation
```{python}
market = pd.DataFrame({
    'minivan': ['A', 'B', 'C', 'D', 'E', 'F'],
    'seat': [7, 6, 8, 7, 6, 7],
    'cargo': ['2ft', '2ft', '2ft', '3ft', '2ft', '2ft'],
    'eng': ['hyb', 'gas', 'gas', 'gas', 'elec', 'hyb'],
    'price': [30, 30, 30, 40, 40, 35]
})
market['seat_7'] = (market['seat'] == 7).astype(int)
market['seat_8'] = (market['seat'] == 8).astype(int)
market['cargo_3ft'] = (market['cargo'] == '3ft').astype(int)
market['eng_hyb'] = (market['eng'] == 'hyb').astype(int)
market['eng_elec'] = (market['eng'] == 'elec').astype(int)
market['utility'] = (estimated_beta_conjoint[0] * market['seat_7'] +
                     estimated_beta_conjoint[1] * market['seat_8'] +
                     estimated_beta_conjoint[2] * market['cargo_3ft'] +
                     estimated_beta_conjoint[3] * market['eng_hyb'] +
                     estimated_beta_conjoint[4] * market['eng_hyb'] +
                     estimated_beta_conjoint[5] * market['price'])
market['exp_utility'] = np.exp(market['utility'])
market['market_share'] = market['exp_utility'] / market['exp_utility'].sum()
```
::::

The predicted market shares are shown below:
```{python}
#| echo: false
show(market[['minivan', 'market_share']])
```

- Minivan B has the highest predicted market share at 46.2%.
- Minivan C also have a decent amount of market share at 34.0%.
- Minivans with higher prices and non gas engines tend to have lower market shares.







