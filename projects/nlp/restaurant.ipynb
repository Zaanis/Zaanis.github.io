{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Restaurant Category Prediction\n",
        "image: CD.png\n",
        "format:\n",
        "  html:\n",
        "    math: katex\n",
        "    toc: true\n",
        "    toc-depth: 2\n",
        "---"
      ],
      "id": "f1554ab5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# About this project\n",
        "The goal of this project is to predict the restaurant type using details about the restaurant and their reviews. There is also a [Kaggle Competition Page](https://www.kaggle.com/competitions/mgta-415-winter2024/leaderboard?) associated with this project.\n",
        "\n",
        "## Leaderboard\n",
        "This is my position on the Kaggle Leader Board:\n",
        "![Private Leaderboard](public.png)\n",
        "![Public Leaderboard](private.png)\n",
        "\n",
        "# Data\n",
        "The data is collected from Yelp restaurant reviews, data contains unstructured features and variables. While I mainly focused on the customer reviews, I've also incorporated some of the other features.\n",
        "\n",
        "# Text Preprocessing "
      ],
      "id": "ab83a882"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def preprocess_df(df, stemming=False):\n",
        "    # get English stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    stop_words.add('would')\n",
        "    stop_words.add('The')\n",
        "    # prepare translation table to translate punctuation to space\n",
        "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
        "    preprocessed_sentences = []\n",
        "    for i, row in df.iterrows():\n",
        "        sent = row[\"text\"]\n",
        "        sent_nopuncts = sent.translate(translator)\n",
        "        words_list = sent_nopuncts.strip().split()\n",
        "        if stemming == True:\n",
        "            words_list = [ps.stem(word) for word in words_list]\n",
        "        filtered_words = [word for word in words_list if word not in stop_words and len(word) != 1] # also skip space from above translation\n",
        "        preprocessed_sentences.append(\" \".join(filtered_words))\n",
        "    df[\"text\"] = preprocessed_sentences\n",
        "    return df"
      ],
      "id": "97d0c87e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "to preprocess the text, I removed the stop words and tested out stemmming, with the conclusion of without stemming, the model performs better.\n",
        "# Text Representation\n",
        "To transform the text into numerical features for ML models to process, I've tested Word2Vec, CBOW, skip-gram and TFIDF. I found that TFIDF significantly improved the accuracy, likely due to its ability to empasize important words."
      ],
      "id": "3fcc6ba5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# tfidf = TfidfVectorizer(strip_accents=None,\n",
        "                        # lowercase=True,\n",
        "                        # preprocessor=None,\n",
        "                        # tokenizer=word_tokenize,\n",
        "                        # use_idf=True,\n",
        "                        # norm='l2',\n",
        "                        # smooth_idf=True,\n",
        "                        # stop_words= 'english',\n",
        "                        # max_df=0.4,\n",
        "                        # sublinear_tf=True)"
      ],
      "id": "670c85b5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Other features\n",
        "As I've stated above, I also included other features in addition to the text, after preprocessing these texts, I then included these features with the tfidf features. I than applied MinMaxScaler to ensure that the additional features are scaled such that the largest value is the largest value in the TFIDF vector.\n",
        "\n",
        "The MinMaxScaler step is important as it ensured that no single type of feature dominates the others due to differences in scale\n",
        "\n",
        "# Model\n",
        "To predict the category, I used a simple logistic regression. I've also tried other classifiers but did not find any significant improvements to the accuracy.\n",
        "\n",
        "# Post Prediciton Processing\n",
        "After generating predictions, I manually adjusted them if a restaurant appeared in both the training and test datasets. However, I observed that many restaurants, particularly fast-food chains, were associated with multiple categories. For instance, Taco Bell was categorized as Mexican in one instance and American in another. To address this inconsistency, I refined the training dataset by removing restaurants with multiple categories. I retained only those restaurants that had more than two entries and a consistent category assignment in the training dataset for the prediction process.\n",
        "![Getting correct labels](p1.png)\n",
        "![Overwrite Predictions](overwrite.png)\n",
        "\n",
        "# Links \n",
        "For project repo:[click here](https://github.com/Zaanis/Restaurant-Prediction)\n"
      ],
      "id": "0b161537"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}